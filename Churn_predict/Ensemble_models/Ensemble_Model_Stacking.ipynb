{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Customer Churn -  Ensemble Learning \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#![churn_bank.jpg](attachment:churn_bank.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importando Bibliotecas \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-06T02:58:11.067609Z",
     "iopub.status.busy": "2025-01-06T02:58:11.067254Z",
     "iopub.status.idle": "2025-01-06T02:58:17.183118Z",
     "shell.execute_reply": "2025-01-06T02:58:17.182230Z",
     "shell.execute_reply.started": "2025-01-06T02:58:11.067582Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import logging\n",
    "import optuna\n",
    "import xgboost as xgb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import shap\n",
    "import lime.lime_tabular\n",
    "import scipy.sparse\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "from xgboost import plot_importance\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.preprocessing import StandardScaler #, MinMaxScaler, RobustScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    matthews_corrcoef, cohen_kappa_score, balanced_accuracy_score,\n",
    "    roc_curve, confusion_matrix, auc\n",
    ")\n",
    "\n",
    "from optuna.samplers import TPESampler\n",
    "import pickle\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import joblib\n",
    "\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import math\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################### para KAGGLE ################################################################################################################\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "########################################################################################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dicinário de Dados \n",
    "\n",
    "\n",
    "| **Variável**         | **Tipo**   | **Descrição**                                                                                                                                     |\n",
    "|-----------------------|------------|---------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| RowNumber            | int64      | Número do registro (linhas), sem efeito na construção de modelos.                                                                                |\n",
    "| CustomerId           | int64      | ID do cliente, sem efeito sobre o estudo.                                                                                                       |\n",
    "| Surname              | object     | Sobrenome do cliente, sem impacto na análise.                                                                                                   |\n",
    "| CreditScore          | int64      | Pontuação de crédito, pode indicar tendência de permanência de clientes com pontuação alta.                                                     |\n",
    "| Geography            | object     | Localização do cliente, pode influenciar a decisão de evasão.                                                                                   |\n",
    "| Gender               | object     | Gênero do cliente, possível influência na evasão.                                                                                               |\n",
    "| Age                  | int64      | Idade do cliente, clientes mais velhos tendem a permanecer.                                                                                     |\n",
    "| Tenure               | int64      | Anos que o cliente está no banco, clientes novos têm maior chance de evasão.                                                                    |\n",
    "| Balance              | float64    | Saldo na conta, pessoas com saldos altos são menos propensas a sair.                                                                            |\n",
    "| NumOfProducts        | int64      | Número de produtos adquiridos pelo cliente.                                                                                                    |\n",
    "| HasCrCard            | int64      | Indica se o cliente tem cartão de crédito, clientes com cartão são menos propensos à evasão.                                                    |\n",
    "| IsActiveMember       | int64      | Clientes ativos têm menor chance de evasão.                                                                                                    |\n",
    "| EstimatedSalary      | float64    | Salário estimado, clientes com salários mais altos tendem a permanecer.                                                                         |\n",
    "| Exited               | int64      | Indica se o cliente saiu ou não do banco, variável de predição (“churn”).                                                                       |\n",
    "| Complain             | int64      | Indica se o cliente fez reclamação.                                                                                                             |\n",
    "| Satisfaction Score   | int64      | Pontuação de satisfação com a resolução de reclamação.                                                                                          |\n",
    "| Card Type            | object     | Tipo de cartão que o cliente possui.                                                                                                            |\n",
    "| Points Earned        | int64      | Pontos ganhos pelo cliente.                                                                                                                     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise Exploratória (EDA) & Data Wrangling \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T02:58:17.184914Z",
     "iopub.status.busy": "2025-01-06T02:58:17.184385Z",
     "iopub.status.idle": "2025-01-06T02:58:17.242602Z",
     "shell.execute_reply": "2025-01-06T02:58:17.241910Z",
     "shell.execute_reply.started": "2025-01-06T02:58:17.184876Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# base_original = pd.read_csv('/kaggle/input/Customer-Churn-Records.csv', sep=',') #KAGGLE\n",
    "base_original = pd.read_csv('C:/Users/jgeov/iCloudDrive/Treinamento/Treinamento Data Science/Projetos/Customer-Churn-Records.csv',sep=',') #LOCAL\n",
    "\n",
    "#configs para nao quebrar linhas no print do  df\n",
    "pd.set_option('display.expand_frame_repr', False) \n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#primeiras linhas \n",
    "base_original.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analisando primeiras impressões da base de dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T02:58:17.244145Z",
     "iopub.status.busy": "2025-01-06T02:58:17.243929Z",
     "iopub.status.idle": "2025-01-06T02:58:17.249149Z",
     "shell.execute_reply": "2025-01-06T02:58:17.248352Z",
     "shell.execute_reply.started": "2025-01-06T02:58:17.244127Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Dimensões \n",
    "print(\"Numero de linhas:\", base_original.shape[0]) \n",
    "print(\"Numero de colunas:\", base_original.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T02:58:17.250489Z",
     "iopub.status.busy": "2025-01-06T02:58:17.250208Z",
     "iopub.status.idle": "2025-01-06T02:58:17.263709Z",
     "shell.execute_reply": "2025-01-06T02:58:17.262879Z",
     "shell.execute_reply.started": "2025-01-06T02:58:17.250461Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#tipos\n",
    "base_original.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T02:58:17.264717Z",
     "iopub.status.busy": "2025-01-06T02:58:17.264514Z",
     "iopub.status.idle": "2025-01-06T02:58:17.392219Z",
     "shell.execute_reply": "2025-01-06T02:58:17.391568Z",
     "shell.execute_reply.started": "2025-01-06T02:58:17.264700Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#checando se há valores nulos \n",
    "base_original.isnull().sum()  \n",
    "#valores nulos nao encontrados "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contando a quantidade de zeros em cada coluna para verificar se elas tem \n",
    "# informacao suficiente para entrar no modelo futuramente\n",
    "\n",
    "for col in base_original.columns:\n",
    "    zero_count = (base_original[col] == 0).sum()\n",
    "    print(\"\")\n",
    "    print(f\" '{col}': {zero_count} valores zero\")\n",
    "\n",
    "#nao foi constatao nada muito impactante, as variaveis com mais zero sao categoriacas (binarias) \n",
    "# Balance seria a unica a se preocupar, mas vamos manter. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T02:58:17.427362Z",
     "iopub.status.busy": "2025-01-06T02:58:17.427052Z",
     "iopub.status.idle": "2025-01-06T02:58:17.437914Z",
     "shell.execute_reply": "2025-01-06T02:58:17.437076Z",
     "shell.execute_reply.started": "2025-01-06T02:58:17.427328Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#removidas por serem meramente identificadoras: RowNumber, CustomerId e Surname\n",
    "\n",
    "#removida Gender por poder inviesar o modelo de alguma formna descriminativa, é uma boa pratica de LGPD nao usar dados sensiveis como esse etc. \n",
    " \n",
    "\n",
    "df = base_original[['CreditScore',\n",
    "                    #'Gender',\n",
    "                    'Geography',\n",
    "                    'Age',\n",
    "                    'Tenure',\n",
    "                    'Balance',\n",
    "                   'NumOfProducts',\n",
    "                    'HasCrCard',\n",
    "                    'IsActiveMember',\n",
    "                   'EstimatedSalary',\n",
    "                    'Complain',\n",
    "                    'Satisfaction Score',\n",
    "                   'Card Type',\n",
    "                    'Point Earned',\n",
    "                    'Exited'\n",
    "                   ]]\n",
    "\n",
    "# Resumo estatístico \n",
    "quanti = df[['EstimatedSalary', 'Balance', 'CreditScore', 'Age', 'Tenure', 'Point Earned']]\n",
    "resumo_estati_quant = quanti.describe().style.format(lambda x: f'{x:,.1f}'.replace(',', 'X').replace('.', ',').replace('X', '.')) # Formatação com 1 casa decimal e separadores invertidos\n",
    "\n",
    "resumo_estati_quant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Resumo estatistico de variaveis qualitativas (frequancias)\n",
    "\n",
    "* Os resumos estatisticos sao importantes para primeiras nocoes de desbalance, a amplitude e distribuicao de valores\n",
    "minimos maximos e um breve entendimento se serao necessarios tratamentos nessas variaveis, decorrentes dessas observacoes; \n",
    "\n",
    "* Podemos notar que a principio as ditribuicoes nao sao absurdas e o desbalance esta pricipalemnte nas variavies Complain e Exited (variavel alvo do estudo, a chamaremos de churn) indicando que sera necessario tratar isso;\n",
    "\n",
    "* Franca tem mais observacoes que os demais paises; \n",
    "\n",
    "* A maioria dos clientes tem cartao de credito; \n",
    "\n",
    "* A maioria dos clientes tem entre 1 e 2 produtos. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-06T02:58:17.497672Z",
     "iopub.status.busy": "2025-01-06T02:58:17.497469Z",
     "iopub.status.idle": "2025-01-06T02:58:18.130862Z",
     "shell.execute_reply": "2025-01-06T02:58:18.130014Z",
     "shell.execute_reply.started": "2025-01-06T02:58:17.497645Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Resumo estatistico \n",
    "\n",
    "#separando quali's para analise \n",
    "quali = df[['HasCrCard', \n",
    "            'IsActiveMember', \n",
    "            'Geography',\n",
    "            #'Gender',\n",
    "            'Complain',\n",
    "            'Exited',\n",
    "            'Card Type',\n",
    "            'NumOfProducts',\n",
    "            'Satisfaction Score']]\n",
    "\n",
    "quali = quali.astype('object')\n",
    "\n",
    "#quali.dtypes\n",
    "\n",
    "\n",
    "\n",
    "def add_value_labels(ax):\n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        color = p.get_facecolor()\n",
    "        ax.text(p.get_x() + p.get_width() / 2., height / 2.,\n",
    "                f'{int(height)}',\n",
    "                ha='center', va='center', fontsize=20, color='white', fontweight='bold',\n",
    "                bbox=dict(facecolor=color, edgecolor='none', alpha=0.7,\n",
    "                          boxstyle='round,pad=0.4', linewidth=1))\n",
    "\n",
    "plt.figure(figsize=(20, 25))\n",
    "\n",
    "# Geography\n",
    "plt.subplot(5, 2, 1)\n",
    "ax1 = plt.gca()\n",
    "ax1.set_title('Geography', fontsize=22, fontweight='bold')\n",
    "sns.countplot(x='Geography', hue='Geography', palette='viridis', data=base_original, ax=ax1, legend=False)\n",
    "plt.xlabel('') \n",
    "plt.ylabel('') \n",
    "plt.xticks(fontsize=15, rotation=0, fontweight='bold')\n",
    "plt.yticks([])\n",
    "add_value_labels(ax1)\n",
    "\n",
    "\n",
    "# Complain\n",
    "plt.subplot(5, 2, 2)\n",
    "ax10 = plt.gca()\n",
    "ax10.set_title('Complain', fontsize=22, fontweight='bold')\n",
    "sns.countplot(x='Complain', hue='Complain', palette='viridis', data=base_original, ax=ax10, legend=False)\n",
    "plt.xlabel('') \n",
    "plt.ylabel('') \n",
    "plt.xticks(fontsize=15, rotation=0, fontweight='bold')\n",
    "plt.yticks([])\n",
    "add_value_labels(ax10)\n",
    "\n",
    "# HasCrCard\n",
    "plt.subplot(5, 2, 3)\n",
    "ax5 = plt.gca()\n",
    "ax5.set_title('HasCrCard', fontsize=22, fontweight='bold')\n",
    "sns.countplot(x='HasCrCard', hue='HasCrCard', palette='viridis', data=base_original, ax=ax5, legend=False)\n",
    "plt.xlabel('') \n",
    "plt.ylabel('') \n",
    "plt.xticks(fontsize=15, rotation=0, fontweight='bold')\n",
    "plt.yticks([])\n",
    "add_value_labels(ax5)\n",
    "\n",
    "# IsActiveMember\n",
    "plt.subplot(5, 2, 4)\n",
    "ax6 = plt.gca()\n",
    "ax6.set_title('IsActiveMember', fontsize=22, fontweight='bold')\n",
    "sns.countplot(x='IsActiveMember', hue='IsActiveMember', palette='viridis', data=base_original, ax=ax6, legend=False)\n",
    "plt.xlabel('') \n",
    "plt.ylabel('') \n",
    "plt.xticks(fontsize=15, rotation=0, fontweight='bold')\n",
    "plt.yticks([])\n",
    "add_value_labels(ax6)\n",
    "\n",
    "# Card Type\n",
    "plt.subplot(5, 2, 5)\n",
    "ax10 = plt.gca()\n",
    "ax10.set_title('Card Type', fontsize=22, fontweight='bold')\n",
    "sns.countplot(x='Card Type', hue='Card Type', palette='viridis', data=base_original, ax=ax10, legend=False)\n",
    "plt.xlabel('') \n",
    "plt.ylabel('') \n",
    "plt.xticks(fontsize=15, rotation=0, fontweight='bold')\n",
    "plt.yticks([])\n",
    "add_value_labels(ax10)\n",
    "\n",
    "\n",
    "# NumOfProducts\n",
    "plt.subplot(5, 2, 6)\n",
    "ax10 = plt.gca()\n",
    "ax10.set_title('NumOfProducts', fontsize=22, fontweight='bold')\n",
    "sns.countplot(x='NumOfProducts', hue='NumOfProducts', palette='viridis', data=base_original, ax=ax10, legend=False)\n",
    "plt.xlabel('') \n",
    "plt.ylabel('') \n",
    "plt.xticks(fontsize=15, rotation=0, fontweight='bold')\n",
    "plt.yticks([])\n",
    "add_value_labels(ax10)\n",
    "\n",
    "\n",
    "# Satisfaction Score\n",
    "plt.subplot(5, 2, 7)\n",
    "ax11 = plt.gca()\n",
    "ax11.set_title('Satisfaction Score', fontsize=22, fontweight='bold')\n",
    "sns.countplot(x='Satisfaction Score', hue='Satisfaction Score', palette='viridis', data=base_original, ax=ax11, legend=False)\n",
    "plt.xlabel('') \n",
    "plt.ylabel('') \n",
    "plt.xticks(fontsize=15, rotation=0, fontweight='bold')\n",
    "plt.yticks([])\n",
    "add_value_labels(ax11)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Exited\n",
    "plt.subplot(5, 2, 8)\n",
    "ax11 = plt.gca()\n",
    "ax11.set_title('Exited: Churn ', fontsize=22, fontweight='bold')\n",
    "custom_palette = ['green', 'red']\n",
    "sns.countplot(x='Exited', hue='Exited', palette=custom_palette, data=base_original, ax=ax11, legend=False)\n",
    "plt.xlabel('') \n",
    "plt.ylabel('') \n",
    "plt.xticks(fontsize=15, rotation=0, fontweight='bold')\n",
    "plt.yticks([])\n",
    "add_value_labels(ax11)\n",
    "\n",
    "ax11.set_xticks([0, 1])\n",
    "ax11.set_xticklabels(['Não', 'Sim'], fontsize=15, fontweight='bold')\n",
    "\n",
    "# Ajustando espaçamento\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Visualizando o comportmento da variavel alvo (exited) em relacao as demais variaveis; \n",
    "\n",
    "* Vemos claramente que existe o disbalance de classes na variavel churn, pela cor verde presente fortemente em todas variaveis, posteriormente isso sera tratado/mitigado; \n",
    "\n",
    "* Ja e possivel notar um forte indicio de alta correlacao entre churn e complain, posteriormente isso sera testado. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Variável alvo em relação as demais variáveis \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(20, 25)) #tamanho do painel grafico\n",
    "\n",
    "#funcao de adicao de legenda no canto superior direito e garante rotulos \n",
    "def add_legend(ax):\n",
    "    \n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    if not handles:\n",
    "        \n",
    "        # Se não houver handles, forca a adicao\n",
    "        handles = [plt.Rectangle((0,0),1,1, color=c) for c in ['green', 'red']]\n",
    "        labels = ['Not Exited', 'Exited']\n",
    "        \n",
    "    # Adiciona a legenda fora da área das barras\n",
    "    ax.legend(handles, labels, loc='upper left', fontsize=14, title='Exited', title_fontsize='13',  \n",
    "              bbox_to_anchor=(1.0, 1)) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Geography\n",
    "plt.subplot(5, 2, 1)\n",
    "counts = base_original.groupby(['Geography', 'Exited']).size().unstack().fillna(0)\n",
    "ax = counts.plot(kind='bar', stacked=True, color=['green', 'red'], ax=plt.gca())  \n",
    "plt.title('Exited by Geography', fontsize=22, fontweight='bold')\n",
    "plt.xlabel('Geography', fontsize=16)\n",
    "plt.ylabel('', fontsize=16)\n",
    "plt.xticks(fontsize=14, rotation=0,fontweight='bold')\n",
    "plt.yticks(fontsize=14)\n",
    "add_legend(ax)\n",
    "\n",
    "\n",
    "# NumOfProducts\n",
    "plt.subplot(5, 2, 2)\n",
    "counts = base_original.groupby(['NumOfProducts', 'Exited']).size().unstack().fillna(0)\n",
    "ax = counts.plot(kind='bar', stacked=True, color=['green', 'red'], ax=plt.gca())  \n",
    "plt.title('Exited by NumOfProducts', fontsize=22, fontweight='bold')\n",
    "plt.xlabel('NumOfProducts', fontsize=16)\n",
    "plt.ylabel('', fontsize=16)\n",
    "plt.xticks(fontsize=14, rotation=0,fontweight='bold')\n",
    "plt.yticks(fontsize=14)\n",
    "add_legend(ax)\n",
    "\n",
    "# HasCrCard\n",
    "plt.subplot(5, 2, 3)\n",
    "counts = base_original.groupby(['HasCrCard', 'Exited']).size().unstack().fillna(0)\n",
    "ax = counts.plot(kind='bar', stacked=True, color=['green', 'red'], ax=plt.gca())  \n",
    "plt.title('Exited by HasCrCard', fontsize=22, fontweight='bold')\n",
    "plt.xlabel('HasCrCard', fontsize=16)\n",
    "plt.ylabel('', fontsize=16)\n",
    "plt.xticks(fontsize=14, rotation=0,fontweight='bold')\n",
    "plt.yticks(fontsize=14)\n",
    "add_legend(ax)\n",
    "\n",
    "# IsActiveMember\n",
    "plt.subplot(5, 2, 4)\n",
    "counts = base_original.groupby(['IsActiveMember', 'Exited']).size().unstack().fillna(0)\n",
    "ax = counts.plot(kind='bar', stacked=True, color=['green', 'red'], ax=plt.gca()) \n",
    "plt.title('Exited by IsActiveMember', fontsize=22, fontweight='bold')\n",
    "plt.xlabel('IsActiveMember', fontsize=16)\n",
    "plt.ylabel('', fontsize=16)\n",
    "plt.xticks(fontsize=14, rotation=0,fontweight='bold')\n",
    "plt.yticks(fontsize=14)\n",
    "add_legend(ax)\n",
    "\n",
    "# Complain\n",
    "plt.subplot(5, 2, 5)\n",
    "counts = base_original.groupby(['Complain', 'Exited']).size().unstack().fillna(0)\n",
    "ax = counts.plot(kind='bar', stacked=True, color=['green', 'red'], ax=plt.gca())  \n",
    "plt.title('Exited by Complain', fontsize=22, fontweight='bold')\n",
    "plt.xlabel('Complain', fontsize=16)\n",
    "plt.ylabel('', fontsize=16)\n",
    "plt.xticks(fontsize=14, rotation=0,fontweight='bold')\n",
    "plt.yticks(fontsize=14)\n",
    "add_legend(ax)\n",
    "\n",
    "# Satisfaction Score\n",
    "plt.subplot(5, 2, 6)\n",
    "counts = base_original.groupby(['Satisfaction Score', 'Exited']).size().unstack().fillna(0)\n",
    "ax = counts.plot(kind='bar', stacked=True, color=['green', 'red'], ax=plt.gca())  \n",
    "plt.title('Exited by Satisfaction Score', fontsize=22, fontweight='bold')\n",
    "plt.xlabel('Satisfaction Score', fontsize=16)\n",
    "plt.ylabel('', fontsize=16)\n",
    "plt.xticks(fontsize=14, rotation=0,fontweight='bold')\n",
    "plt.yticks(fontsize=14)\n",
    "add_legend(ax)\n",
    "\n",
    "# Card Type\n",
    "plt.subplot(5, 2, 7)\n",
    "counts = base_original.groupby(['Card Type', 'Exited']).size().unstack().fillna(0)\n",
    "ax = counts.plot(kind='bar', stacked=True, color=['green', 'red'], ax=plt.gca())  \n",
    "plt.title('Exited by Card Type', fontsize=22, fontweight='bold')\n",
    "plt.xlabel('Card Type', fontsize=16)\n",
    "plt.ylabel('', fontsize=16)\n",
    "plt.xticks(fontsize=14, rotation=0,fontweight='bold')\n",
    "plt.yticks(fontsize=14)\n",
    "add_legend(ax)\n",
    "\n",
    "# Ajusta a distância entre os gráficos\n",
    "plt.subplots_adjust(hspace=0.7, wspace=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variaveis Dummies\n",
    "\n",
    "* A maioria dos modelos necessita de transformar as variaveis categoricas em numericas, e o modelo atual e um deles; \n",
    "\n",
    "* A transformacao de categoricas em numericas precisa ser feita com processos adequados para nao cometer ponderacao arbitrária no desenvolvimento. \n",
    "\n",
    "* foi aplicado one-hot encoding para isso. Esse processo e chamado de \"Dummizacao\". \n",
    "\n",
    "* foi necessario aplicar Ordinal-Encoder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dumizando\n",
    "\n",
    "# Suprime todos os warnings de futuro (deixa mais clean)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "# Lista de variáveis a serem transformadas\n",
    "cols_to_transform = ['Geography']\n",
    "\n",
    "# Convertendo para string (somente a coluna \"Geography\")\n",
    "df.loc[:, cols_to_transform] = df.loc[:, cols_to_transform].astype(str)\n",
    "\n",
    "# Realizando o One-Hot Encoding \n",
    "df_dummies = pd.get_dummies(df, columns=cols_to_transform, dtype=int, drop_first=True) \n",
    "#se o modelo/modelos forem afetados drasticamntee por multicolineariadde drop_first=True deve ser melhor, pois dropa uma das variaveis dummie. Os demais nao feta tanto, mas e boa pratica\n",
    "\n",
    "# Ordinal-Encoder \n",
    "df_dummies['Card Type'] = OrdinalEncoder(categories=[[\"SILVER\", \"GOLD\", \"PLATINUM\", \"DIAMOND\"]], dtype=int).fit_transform(df_dummies[['Card Type']])\n",
    "\n",
    "# Variável alvo 'Exited' para o tipo numérico (se necessário)\n",
    "df_dummies['Exited'] = df_dummies['Exited'].astype('int64')\n",
    "\n",
    "print(df_dummies.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separação Treino e Teste & Adicao de Features quadráticas\n",
    "\n",
    "* A separacao em treino e teste alem de uma boa pratica e extreamente necessario na construcao de modelos de machine learning; \n",
    "\n",
    "* Tambem foram adicionadas variaveis quadraticas, ou seja, com operacao matematica aplicadas em variaveis originais gerando novas variaveis. Isso foi feito para capturar algum tipo de comportamento nao linear; \n",
    "\n",
    "* Foi considerado aplicar transformacao polinomial nas variaveis, por isso foi primeiro aplicado o termo quadratico, que nao apresentou melhoria significativa a ponto de aplicarmos polinomias; \n",
    "\n",
    "* Alem disso esse modelo captura naturalmente comportamentos nao lineares. O termo quadratico foi util para validacao durante o estudo mas a melhoria foi baixa, por isso mantemos apenas os termos quadraticos sem incluir interacoes entre variaveis (seria aplicacao Polinomias completo); \n",
    "\n",
    "\n",
    "\n",
    "* Tambem e possivel notar o desbalanceamento das classes  nas bases tanto em treino quanto em teste no grafico final; \n",
    "\n",
    "* Tambem garantimos a mesma proporcao (80/20) tanto em treino quanto em teste na separacao das bases , ou seja, equidade de divisao de dados e equilibrio. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X ---> Variáveis explicativas \n",
    "#Y ---> Evento de estudo (variável TARGET, evento de estudo, ^y etc..)\n",
    "\n",
    "df_dummies = df_dummies.drop(columns=['Complain']) #correlacao altissima com a variavel alvo\n",
    "\n",
    "\n",
    "X = df_dummies .drop('Exited', axis=1)\n",
    "\n",
    "# VARIAVEIS QUADRATICAS \n",
    "X['Balance_Squared'] = X['Balance'] ** 2\n",
    "X['Age_Squared'] = X['Age'] ** 2\n",
    "X['CreditScore_Squared'] = X['CreditScore'] ** 2\n",
    "X['Tenure_Squared'] = X['Tenure'] ** 2\n",
    "X['EstimatedSalary_Squared'] = X['EstimatedSalary'] ** 2\n",
    "\n",
    "\n",
    "\n",
    "y =  df_dummies['Exited']\n",
    "\n",
    "\n",
    "#separando em treino e teste \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Visualizando a proporção de eventos de churn (TARGET) nas bases de TREINO e TESTE \n",
    "\n",
    "# Contando os valores \n",
    "churn_counts_train = y_train.value_counts()\n",
    "churn_counts_test = y_test.value_counts()\n",
    "\n",
    "\n",
    "# plot que contem os graficos\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "fig.suptitle('Proporção da Variável Churn entre Treino e Teste', fontsize=35)  \n",
    "cmap = plt.get_cmap('viridis', 2) #paleta de cores\n",
    "\n",
    "\n",
    "\n",
    "# Gráfico da base de treino\n",
    "bars_train = axs[0].bar(churn_counts_train.index, churn_counts_train.values, color=cmap(range(2)))\n",
    "axs[0].set_title('Base de Treino', fontsize=25)\n",
    "axs[0].set_xlabel('Churn', fontsize=20)\n",
    "axs[0].set_ylabel('Contagem', fontsize=20)\n",
    "axs[0].set_xticks([0, 1])\n",
    "axs[0].set_xticklabels(['0', '1'], fontsize=20)\n",
    "axs[0].set_yticklabels([]) # Ocultando os valores do eixo y\n",
    "\n",
    "# Adicionando rótulos de dados\n",
    "total_train = churn_counts_train.sum()\n",
    "for bar in bars_train:\n",
    "    count = int(bar.get_height())\n",
    "    percentage = round(count / total_train * 100)  # Arredonda a porcentagem\n",
    "    label = f'{count} ({percentage}%)'  #valor absoluto e o percentual\n",
    "    axs[0].text(bar.get_x() + bar.get_width() / 2, bar.get_height() / 2, \n",
    "                label, ha='center', color='gray', fontsize=25, weight='bold')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Gráfico da base de teste\n",
    "bars_test = axs[1].bar(churn_counts_test.index, churn_counts_test.values, color=cmap(range(2)))\n",
    "axs[1].set_title('Base de Teste', fontsize=25)\n",
    "axs[1].set_xlabel('Churn', fontsize=20)\n",
    "axs[1].set_ylabel('Contagem', fontsize=20)\n",
    "axs[1].set_xticks([0, 1])\n",
    "axs[1].set_xticklabels(['0', '1'], fontsize=20)\n",
    "axs[1].set_yticklabels([])# Ocultando os valores do eixo y\n",
    "\n",
    "# Adicionando rótulos de dados\n",
    "total_test = churn_counts_test.sum()\n",
    "for bar in bars_test:\n",
    "    count = int(bar.get_height())\n",
    "    percentage = round(count / total_test * 100)  # Arredonda a porcentagem\n",
    "    label = f'{count} ({percentage}%)'  #valor absoluto e o percentual\n",
    "    axs[1].text(bar.get_x() + bar.get_width() / 2, bar.get_height() / 2, \n",
    "                label, ha='center', color='gray', fontsize=25, weight='bold')\n",
    "\n",
    "\n",
    "\n",
    "# Ajusta o layout para evitar sobreposição\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])  # forca espaco para o titulo\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verificando correlacoes depois de construcao total de features e Dummizacao \n",
    "\n",
    "* Verificar as correlacoes e extreammente importante, elas podem indicar a famosa multicolinearidade, que atrapalha a maioria dos modelos; \n",
    "\n",
    "* no caso da deste modelo (pelo menos a presente aplicacao) ela nao afetou, a observei com atencao, mas nao impactou. Decidi manter as variveis mesmo com multicolinearidade em algumas (nao se assuste). \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Observando Multicolinearidade na base de treino\n",
    "\n",
    "teste_multco_treino = pd.concat([X_train,y_train], axis = 1)\n",
    "\n",
    "correlation_matrix_treino = teste_multco_treino.corr().round(2)\n",
    "correlation_matrix_treino\n",
    "\n",
    "# Matrix com  mapa de calor \n",
    "plt.figure(figsize=(30, 20))\n",
    "heatmap = sns.heatmap(correlation_matrix_treino, annot=True, fmt=\".2f\",\n",
    "                      cmap=plt.cm.viridis_r, # paleta de cores viridis (ou viridis_r para o inverso de cores) é uma paleta especial \n",
    "                                             # para facilitar a visualizacao por pessoas com dificuldades visuais, como os daltonicos. \n",
    "                      annot_kws={'size': 15}, vmin=-1, vmax=1)\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(), fontsize=17)\n",
    "heatmap.set_yticklabels(heatmap.get_yticklabels(), fontsize=17)\n",
    "plt.title('Correlação das Variáveis Quantitativas na Base de Treino',fontsize=25)\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analise e tratamento de Outliers \n",
    "\n",
    "* Outliers sao numericos e podem afetar de diversas formas modelos; \n",
    "\n",
    "* para resolver sem perder dados, pois temos poucas observcoes para estudo, nao foram removidos como facilmente poderia fazer-se, ao inves foi aplicado winsorization; \n",
    "\n",
    "* winsorization e uma tecnica de limitacao dos outliers, ela substiui os valores de outlierns pelos limites superiores e inferiores; \n",
    "\n",
    "* Para isso, e calculado um intervalo de valores aceitos com base no primeiro quartil (Q1) e no terceiro quartil (Q3), valores abaixo do limite inferior ou acima do limite superior sao ajustados para os respectivos limites, corrigindo assim os outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% analise de outliers das variaveis na base de treino \n",
    "\n",
    "\n",
    "###############antes de tratamento############################# \n",
    "variaveis = [\n",
    "    'CreditScore',\n",
    "    'Age',\n",
    "    'Tenure',\n",
    "    'Balance',\n",
    "    'NumOfProducts',\n",
    "    'EstimatedSalary',\n",
    "    'Satisfaction Score',\n",
    "    'Point Earned',\n",
    "    #QUADRATICAS\n",
    "    'Balance_Squared',\n",
    "    'Age_Squared',\n",
    "    'CreditScore_Squared',\n",
    "    'Tenure_Squared',\n",
    "    'EstimatedSalary_Squared'\n",
    "]\n",
    "\n",
    "\n",
    "# definindo tamnhos de subplots \n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "# loop de criacao de boxplots para cada variavel \n",
    "for i, var in enumerate(variaveis):\n",
    "    plt.subplot(5, 4, i + 1)  #determina a grade de plots \n",
    "    sns.boxplot(y=teste_multco_treino[var],\n",
    "               boxprops=dict(facecolor='lightblue'))  # Cor interna do boxplot \n",
    "    plt.title(f'Boxplot {var}', fontsize=12)\n",
    "    \n",
    "#  título geral\n",
    "plt.suptitle('Análise de Outliers nas Variáveis(treino) - antes de \"winsorization\" ', fontsize=20)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95]) # Ajuste de layout\n",
    "plt.show()\n",
    "###############################################################\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Função que aplica winsorization\n",
    "def tratar_outliers(df, coluna):\n",
    "    Q1 = df[coluna].quantile(0.25)\n",
    "    Q3 = df[coluna].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    limite_inferior = Q1 - 1.5 * IQR\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "    # Substitui outliers pelo limite inferior ou superior\n",
    "    df[coluna] = np.where(df[coluna] < limite_inferior, limite_inferior, df[coluna])\n",
    "    df[coluna] = np.where(df[coluna] > limite_superior, limite_superior, df[coluna])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###############depois de tratamento############################# \n",
    "\n",
    "# Aplicando a função nas variáveis \n",
    "variaveis_para_tratar = ['CreditScore',\n",
    "                        'Age',\n",
    "                        'Tenure',\n",
    "                        'Balance',\n",
    "                        'NumOfProducts',\n",
    "                        'EstimatedSalary',\n",
    "                        'Satisfaction Score',\n",
    "                        'Point Earned',\n",
    "                        #QUADRATICAS\n",
    "                        'Balance_Squared',\n",
    "                        'Age_Squared',\n",
    "                        'CreditScore_Squared',\n",
    "                        'Tenure_Squared',\n",
    "                        'EstimatedSalary_Squared'\n",
    "                         ]\n",
    "for variavel in variaveis_para_tratar:\n",
    "    tratar_outliers(teste_multco_treino, variavel)\n",
    "\n",
    "\n",
    "# subplot\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "\n",
    "\n",
    "# loop de criacao de boxplots para cada variavel \n",
    "for i, var in enumerate(variaveis):\n",
    "    plt.subplot(5, 4, i + 1)  #determina a grade de plots \n",
    "    sns.boxplot(y=teste_multco_treino[var],\n",
    "               boxprops=dict(facecolor='green'))  # Cor interna do boxplot\n",
    "    plt.title(f'Boxplot {var}', fontsize=12)\n",
    "########################################################################\n",
    "\n",
    "\n",
    "# título geral\n",
    "plt.suptitle('Análise de Outliers nas Variáveis(treino) - depois de \"winsorization\" ', fontsize=20)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])  # ajusta layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BASE DE TREINO \n",
    "teste_multco_treino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BASE DE TESTE\n",
    "base_corrige_teste = pd.concat([X_test,y_test], axis = 1)\n",
    "base_corrige_teste\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparacao dos dados  \n",
    "\n",
    "\n",
    "* Preparacao dos dados \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('------------------------')\n",
    "print(\" DATA Prep\")\n",
    "print('------------------------')\n",
    "\n",
    "# Desativando os warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='torch')\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='optuna')\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module='optuna')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "logging.getLogger(\"optuna\").setLevel(logging.CRITICAL)\n",
    "\n",
    "\n",
    "\n",
    "# início\n",
    "start_time_utc = datetime.utcnow() - timedelta(hours=3)\n",
    "print('------------------------')\n",
    "print(\"Início:\", start_time_utc)\n",
    "print('------------------------')\n",
    "\n",
    "\n",
    "######################################## PRE-PROCESSAMENTO E PREPARACAO NOS DADOS ################################################################### \n",
    "\n",
    "\n",
    "\n",
    "# Defini variáveis de treinamento\n",
    "X_train = teste_multco_treino.drop('Exited', axis=1)\n",
    "y_train = teste_multco_treino['Exited']\n",
    "\n",
    "# Verifica e conserta desalinhamento de índices caso tenha (X_test e y_test)\n",
    "if not X_test.index.equals(y_test.index):\n",
    "    print(\"Índices de X_test e y_test não estavam alinhados. Realinhando y_test.\")\n",
    "    y_test = y_test.loc[X_test.index]\n",
    "else:\n",
    "    print(\"Índices de X_test e y_test já estavam alinhados.\")\n",
    "\n",
    "# Concatena os dados corrigidos para criar a base de teste\n",
    "base_corrige_teste = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "# Redefini X_test e y_test com índices corrigidos e verificados\n",
    "X_test = base_corrige_teste.drop('Exited', axis=1)\n",
    "y_test = base_corrige_teste['Exited']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Criar e treinar o modelo Random Forest para selecionar as melhores variaveis \n",
    "#detalhe importante, nao tem predict(), somente o fit() \n",
    "rf = RandomForestClassifier(n_estimators=300, random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "# Obter a importância das features\n",
    "feature_importances = rf.feature_importances_\n",
    "\n",
    "# Criar DataFrame com os nomes das features e suas importâncias\n",
    "feature_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': feature_importances})\n",
    "\n",
    "# Filtrar features com importância maior que 0.01 (ou outro threshold desejado)\n",
    "selected_features = feature_df[feature_df['Importance'] > 0.01]['Feature'].tolist()\n",
    "\n",
    "# Ordenar as features pela importância (do menor para o maior)\n",
    "feature_df = feature_df.sort_values(by='Importance', ascending=True)\n",
    "\n",
    "# Criar o gráfico de barras horizontais\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_df['Feature'], feature_df['Importance'], color='skyblue')\n",
    "plt.xlabel('Importância')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Importância das Features Selecionadas (Random Forest)')\n",
    "plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "plt.xticks(np.arange(0, max(feature_df['Importance'])+0.01, 0.01))\n",
    "\n",
    "\n",
    "# Mostrar o gráfico\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finalizando preparacao e selecionando variaveis\n",
    "\n",
    "Variaveis selecionadas conforme o modelo classificador de importancia usado anteriormente (randomforest) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Shape X_train antes de selecionar as fetuares importantes:\", X_train.shape)\n",
    "print(\"Shape y_train antes de selecionar as fetuares importantes:\", y_train.shape)\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "optuna.logging.set_verbosity(optuna.logging.CRITICAL)\n",
    "\n",
    "\n",
    "start_time_utc = datetime.utcnow() - timedelta(hours=3)\n",
    "print(\"Tempo de Início:\", start_time_utc)\n",
    "print('------------------------')\n",
    "\n",
    "\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "X_train, y_train = X_train_selected , y_train\n",
    "X_test, y_test = X_test_selected , y_test\n",
    "\n",
    "print(\"Shape X_train (selecionadas):\", X_train.shape)\n",
    "print(\"Shape y_train (selecionadas):\", y_train.shape)\n",
    "\n",
    "print(\"Shape X_test (selecionadas):\", X_test.shape)\n",
    "print(\"Shape y_test (selecionadas):\", y_test.shape)\n",
    "\n",
    "\n",
    "#verificando alinhamneto\n",
    "assert X_train.shape[0] == y_train.shape[0], \"Erro: Número de amostras não coincide\"\n",
    "assert X_test.shape[0] == y_test.shape[0], \"Erro: Número de amostras não coincide\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ensemble Model - Aplicando modelos salvos anteriormente e conferindo resultados** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Catboost\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    matthews_corrcoef, cohen_kappa_score, balanced_accuracy_score, confusion_matrix, roc_curve\n",
    ")\n",
    "\n",
    "\n",
    "# Caminhos dos arquivos\n",
    "modelo_path = r\"C:\\Users\\jgeov\\OneDrive\\Documentos\\GitHub\\Ciencia_de_dados-1\\Churn_predict\\CATboost\\catboost_model.pkl\"\n",
    "scaler_path = r\"C:\\Users\\jgeov\\OneDrive\\Documentos\\GitHub\\Ciencia_de_dados-1\\Churn_predict\\CATboost\\scaler.pkl\"\n",
    "\n",
    "# Carregar o modelo treinado\n",
    "with open(modelo_path, 'rb') as file:\n",
    "    model_catboost = pickle.load(file)\n",
    "\n",
    "# Carregar o scaler\n",
    "with open(scaler_path, 'rb') as file:\n",
    "    scaler_catboost = pickle.load(file)\n",
    "\n",
    "# Normalizar os dados de teste\n",
    "X_test_scaled = scaler_catboost.transform(X_test_selected)\n",
    "\n",
    "# Fazer previsões\n",
    "y_pred = model_catboost.predict(X_test_scaled)\n",
    "y_pred_proba = model_catboost.predict_proba(X_test_scaled)[:, 1]  # Probabilidade da classe positiva\n",
    "\n",
    "# Converter para DataFrame para análise\n",
    "#df_pred = pd.DataFrame({\n",
    "#    \"y_real\": y_test.values,  # Se `y_test` for DataFrame, pegar `.values`\n",
    "#    \"y_pred\": y_pred,\n",
    "#    \"y_pred_proba\": y_pred_proba\n",
    "#})\n",
    "\n",
    "# Exibir as primeiras linhas das previsões\n",
    "#print(df_pred.head())\n",
    "\n",
    "\n",
    "# Calcular métricas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Exibir as métricas no formato desejado\n",
    "print(\"\\n📊 MÉTRICAS DO MODELO CATboost nos dados de teste\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Métrica':<20}{'Valor final':<15}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Acurácia{' ' * 11}{accuracy:.4f}\")\n",
    "print(f\"Precisão{' ' * 12}{precision:.4f}\")\n",
    "print(f\"Recall{' ' * 14}{recall:.4f}\")\n",
    "print(f\"F1-Score{' ' * 12}{f1:.4f}\")\n",
    "print(f\"AUC-ROC{' ' * 13}{auc_roc:.4f}\")\n",
    "print(f\"MCC{' ' * 17}{mcc:.4f}\")\n",
    "print(f\"Kappa de Cohen{' ' * 7}{kappa:.4f}\")\n",
    "print(f\"Acurácia Balanceada {balanced_acc:.4f}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Criando a figura e os subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Plot da Matriz de Confusão\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Negativo\", \"Positivo\"], \n",
    "            yticklabels=[\"Negativo\", \"Positivo\"], ax=axes[0])\n",
    "axes[0].set_xlabel(\"Predito\")\n",
    "axes[0].set_ylabel(\"Real\")\n",
    "axes[0].set_title(\"Matriz de Confusão (TESTE) - CATboost\")\n",
    "\n",
    "# Plot da Curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "auc_roc_value = auc(fpr, tpr)\n",
    "axes[1].plot(fpr, tpr, label=f\"ROC Curve (AUC = {auc_roc_value:.4f})\", color=\"blue\")\n",
    "axes[1].plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")  # Linha diagonal\n",
    "axes[1].set_xlabel(\"Taxa de Falsos Positivos (FPR)\")\n",
    "axes[1].set_ylabel(\"Taxa de Verdadeiros Positivos (TPR)\")\n",
    "axes[1].set_title(\"Curva ROC (TESTE)- CATboost\")\n",
    "axes[1].legend()\n",
    "\n",
    "# Distribuição de probabilidades\n",
    "\n",
    "# classe positiva\n",
    "probs_pos = y_pred_proba  \n",
    "# classe negativa\n",
    "probs_neg = 1 - y_pred_proba\n",
    "\n",
    "# Plot classe positiva \n",
    "sns.kdeplot(probs_pos, color='blue', ax=axes[2], label='Classe Positiva', fill=True, alpha=0.6)\n",
    "\n",
    "# Plot classe negativa \n",
    "sns.kdeplot(probs_neg, color='red', ax=axes[2], label='Classe Negativa', fill=True, alpha=0.02, linewidth=0.30)\n",
    "\n",
    "# Ajustando o gráfico\n",
    "axes[2].set_title(\"Distribuição das Probabilidades para as Classes Positiva e Negativa (TESTE) - CATboost\")\n",
    "axes[2].set_xlabel(\"Probabilidade\")\n",
    "axes[2].set_ylabel(\"Densidade\")\n",
    "axes[2].legend()\n",
    "# setando eixo de probabilidades entre 0 e 1\n",
    "axes[2].set_xlim(0, 1)\n",
    "\n",
    "\n",
    "# Ajuste de layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP - PyTorch\n",
    "\n",
    "# Classe MLP do modelo (reconstrução exata)\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, hidden_layer_sizes, activation, dropout_rate=0.2):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        for units in hidden_layer_sizes:\n",
    "            self.layers.append(nn.Linear(input_size, units))\n",
    "            self.layers.append(nn.Dropout(p=dropout_rate))\n",
    "            input_size = units\n",
    "        self.output = nn.Linear(input_size, 1)\n",
    "        self.activation_fn = self.get_activation_function(activation)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = self.activation_fn(layer(x))\n",
    "        x = self.output(x)\n",
    "        return x\n",
    "\n",
    "    def get_activation_function(self, activation):\n",
    "        activation_dict = {\n",
    "            'relu': torch.relu,\n",
    "            'tanh': torch.tanh,\n",
    "            'sigmoid': torch.sigmoid,\n",
    "            'selu': torch.selu,\n",
    "            'gelu': torch.nn.functional.gelu,\n",
    "            'leaky_relu': torch.nn.functional.leaky_relu,\n",
    "            'swish': torch.nn.functional.silu,\n",
    "            'elu': torch.nn.functional.elu\n",
    "        }\n",
    "        return activation_dict.get(activation, torch.relu)\n",
    "\n",
    "# Definir o dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Carregar o scaler\n",
    "scaler_mlp_torch = torch.load(r\"C:\\Users\\jgeov\\OneDrive\\Documentos\\GitHub\\Ciencia_de_dados-1\\Churn_predict\\MLP-Pytorch\\scaler.pth\")\n",
    "\n",
    "#salvando para uso dentro desse notebook, uma copia com formato de joblib / pickle\n",
    "joblib.dump(scaler_mlp_torch, \"scaler_mlp_temp.pkl\")\n",
    "\n",
    "#definindo scaler definitivamente\n",
    "scaler_mlp_torch = joblib.load(\"scaler_mlp_temp.pkl\")\n",
    "\n",
    "\n",
    "#apagando scaler_mlp_temp para nao confundir com scaler scaler oficial do ensemble\n",
    "\n",
    "arquivo = \"scaler_mlp_temp.pkl\"\n",
    "if os.path.exists(arquivo):\n",
    "    os.remove(arquivo)\n",
    "    print(f\"Arquivo {arquivo} removido com sucesso.\")\n",
    "else:\n",
    "    print(f\"Arquivo {arquivo} não encontrado.\")\n",
    "\n",
    "\n",
    "\n",
    "# Normalizar os dados de teste\n",
    "X_test_scaled = scaler_mlp_torch.transform(X_test)\n",
    "\n",
    "# Converter X_test para tensor do PyTorch\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
    "\n",
    "# Carregar os hiperparâmetros do modelo (ajuste isso se souber os valores exatos)\n",
    "hidden_layer_sizes = [950, 850]  # com base nos melhores parâmetros encontrados no modelo carregado e treinado anteriormente \n",
    "activation = \"relu\"  # com base nos melhores parâmetros encontrados no modelo carregado e treinado anteriormente \n",
    "dropout_rate = 0.35657230019086544  # com base nos melhores parâmetros encontrados no modelo carregado e treinado anteriormente \n",
    "\n",
    "# Criar a instância do modelo com os hiperparâmetros corretos\n",
    "input_size = X_test.shape[1]\n",
    "model_mlp_torch = MLP(input_size, hidden_layer_sizes, activation, dropout_rate)\n",
    "\n",
    "# Carregar o modelo salvo\n",
    "model_mlp_torch = torch.load(r\"C:\\Users\\jgeov\\OneDrive\\Documentos\\GitHub\\Ciencia_de_dados-1\\Churn_predict\\MLP-Pytorch\\best_model_inteiro.pth\", map_location=device)\n",
    "model_mlp_torch.to(device)\n",
    "model_mlp_torch.eval()\n",
    "\n",
    "# Fazer previsões\n",
    "with torch.no_grad():\n",
    "    # Aplicar a função sigmoide para garantir que as probabilidades estejam no intervalo [0, 1]\n",
    "    y_pred_proba = torch.sigmoid(model_mlp_torch(X_test_tensor)).cpu().numpy().flatten()\n",
    "\n",
    "# Converter probabilidades para rótulos binários (0 ou 1)\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "\n",
    "# Calcular métricas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "auc_roc = roc_auc_score(y_test, y_pred_proba)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Exibir as métricas no formato desejado\n",
    "print(\"\\n📊 MÉTRICAS DO MODELO MLP nos dados de teste\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Métrica':<20}{'Valor final':<15}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Acurácia{' ' * 11}{accuracy:.4f}\")\n",
    "print(f\"Precisão{' ' * 12}{precision:.4f}\")\n",
    "print(f\"Recall{' ' * 14}{recall:.4f}\")\n",
    "print(f\"F1-Score{' ' * 12}{f1:.4f}\")\n",
    "print(f\"AUC-ROC{' ' * 13}{auc_roc:.4f}\")\n",
    "print(f\"MCC{' ' * 17}{mcc:.4f}\")\n",
    "print(f\"Kappa de Cohen{' ' * 7}{kappa:.4f}\")\n",
    "print(f\"Acurácia Balanceada {balanced_acc:.4f}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Criando a figura e os subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Plot da Matriz de Confusão\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Negativo\", \"Positivo\"], \n",
    "            yticklabels=[\"Negativo\", \"Positivo\"], ax=axes[0])\n",
    "axes[0].set_xlabel(\"Predito\")\n",
    "axes[0].set_ylabel(\"Real\")\n",
    "axes[0].set_title(\"Matriz de Confusão (TESTE) - MLP\")\n",
    "\n",
    "# Plot da Curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "auc_roc_value = auc(fpr, tpr)\n",
    "axes[1].plot(fpr, tpr, label=f\"ROC Curve (AUC = {auc_roc_value:.4f})\", color=\"blue\")\n",
    "axes[1].plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")  # Linha diagonal\n",
    "axes[1].set_xlabel(\"Taxa de Falsos Positivos (FPR)\")\n",
    "axes[1].set_ylabel(\"Taxa de Verdadeiros Positivos (TPR)\")\n",
    "axes[1].set_title(\"Curva ROC (TESTE) - MLP\")\n",
    "axes[1].legend()\n",
    "\n",
    "# Distribuição de probabilidades\n",
    "\n",
    "# classe positiva\n",
    "probs_pos = y_pred_proba  \n",
    "# classe negativa\n",
    "probs_neg = 1 - y_pred_proba\n",
    "\n",
    "# Plot classe positiva \n",
    "sns.kdeplot(probs_pos, color='blue', ax=axes[2], label='Classe Positiva', fill=True, alpha=0.6)\n",
    "\n",
    "# Plot classe negativa \n",
    "sns.kdeplot(probs_neg, color='red', ax=axes[2], label='Classe Negativa', fill=True, alpha=0.02, linewidth=0.30)\n",
    "\n",
    "# Ajustando o gráfico\n",
    "axes[2].set_title(\"Distribuição das Probabilidades para as Classes Positiva e Negativa (TESTE) - MLP\")\n",
    "axes[2].set_xlabel(\"Probabilidade\")\n",
    "axes[2].set_ylabel(\"Densidade\")\n",
    "axes[2].legend()\n",
    "# setando eixo de probabilidades entre 0 e 1\n",
    "axes[2].set_xlim(0, 1)\n",
    "\n",
    "# Ajuste de layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost \n",
    "import joblib\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, roc_curve, auc, matthews_corrcoef, cohen_kappa_score, balanced_accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Caminhos dos arquivos\n",
    "model_path = r\"C:\\Users\\jgeov\\OneDrive\\Documentos\\GitHub\\Ciencia_de_dados-1\\Churn_predict\\Xgboost\\xgb_model.pkl\"\n",
    "scaler_path = r\"C:\\Users\\jgeov\\OneDrive\\Documentos\\GitHub\\Ciencia_de_dados-1\\Churn_predict\\Xgboost\\scaler.pkl\"\n",
    "\n",
    "# Carregar o scaler\n",
    "scaler_xgb = joblib.load(scaler_path)\n",
    "\n",
    "# Normalizar os dados de teste\n",
    "X_test_scaled = scaler_xgb.transform(X_test)\n",
    "\n",
    "# Carregar o modelo XGBoost\n",
    "xgb_model = joblib.load(model_path)\n",
    "\n",
    "# Fazer previsões (probabilidades)\n",
    "y_pred_prob = xgb_model.predict(xgb.DMatrix(X_test_scaled))\n",
    "\n",
    "# Converter para classe binária (usando threshold 0.5)\n",
    "y_pred = (y_pred_prob >= 0.5).astype(int)\n",
    "\n",
    "# Calcular métricas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "mcc = matthews_corrcoef(y_test, y_pred)\n",
    "kappa = cohen_kappa_score(y_test, y_pred)\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Exibir métricas no formato esperado\n",
    "print(\"\\n📊 MÉTRICAS DO MODELO XGBOOST nos dados de teste\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Métrica':<22} {'Valor final':<15}\")\n",
    "print(\"-\"*60)\n",
    "print(f\"{'Acurácia':<22} {accuracy:.4f}\")\n",
    "print(f\"{'Precisão':<22} {precision:.4f}\")\n",
    "print(f\"{'Recall':<22} {recall:.4f}\")\n",
    "print(f\"{'F1-Score':<22} {f1:.4f}\")\n",
    "print(f\"{'AUC-ROC':<22} {roc_auc:.4f}\")\n",
    "print(f\"{'MCC':<22} {mcc:.4f}\")\n",
    "print(f\"{'Kappa de Cohen':<22} {kappa:.4f}\")\n",
    "print(f\"{'Acurácia Balanceada':<22} {balanced_acc:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Criando a figura e os subplots\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Plot da Matriz de Confusão\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Negativo\", \"Positivo\"], \n",
    "            yticklabels=[\"Negativo\", \"Positivo\"], ax=axes[0])\n",
    "axes[0].set_xlabel(\"Predito\")\n",
    "axes[0].set_ylabel(\"Real\")\n",
    "axes[0].set_title(\"Matriz de Confusão (TESTE) - XGBoost\")\n",
    "\n",
    "# Plot da Curva ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_prob)\n",
    "roc_auc_value = auc(fpr, tpr)\n",
    "axes[1].plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc_value:.4f})\", color=\"blue\")\n",
    "axes[1].plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")  # Linha diagonal\n",
    "axes[1].set_xlabel(\"Taxa de Falsos Positivos (FPR)\")\n",
    "axes[1].set_ylabel(\"Taxa de Verdadeiros Positivos (TPR)\")\n",
    "axes[1].set_title(\"Curva ROC (TESTE) - XGBoost\")\n",
    "axes[1].legend()\n",
    "\n",
    "# Distribuição de probabilidades\n",
    "\n",
    "# classe positiva\n",
    "probs_pos = y_pred_prob  \n",
    "# classe negativa\n",
    "probs_neg = 1 - y_pred_prob\n",
    "\n",
    "# Plot classe positiva \n",
    "sns.kdeplot(probs_pos, color='blue', ax=axes[2], label='Classe Positiva', fill=True, alpha=0.6)\n",
    "\n",
    "# Plot classe negativa \n",
    "sns.kdeplot(probs_neg, color='red', ax=axes[2], label='Classe Negativa', fill=True, alpha=0.02, linewidth=0.30)\n",
    "\n",
    "# Ajustando o gráfico\n",
    "axes[2].set_title(\"Distribuição das Probabilidades para as Classes Positiva e Negativa (TESTE) - XGBoost\")\n",
    "axes[2].set_xlabel(\"Probabilidade\")\n",
    "axes[2].set_ylabel(\"Densidade\")\n",
    "axes[2].legend()\n",
    "# setando eixo de probabilidades entre 0 e 1\n",
    "axes[2].set_xlim(0, 1)\n",
    "\n",
    "\n",
    "# Ajuste de layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import xgboost as xgb\n",
    "import catboost\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    matthews_corrcoef, cohen_kappa_score, balanced_accuracy_score, confusion_matrix, roc_curve\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Normalizar os dados de teste e treino com os scalers corretos\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "# XGBoost - Escalonamento com o scaler específico para XGBoost\n",
    "X_train_scaled_xgb = scaler_xgb.transform(X_train)\n",
    "X_test_scaled_xgb = scaler_xgb.transform(X_test)\n",
    "\n",
    "# MLP (Torch) - Escalonamento com o scaler específico para MLP\n",
    "X_train_scaled_mlp = scaler_mlp_torch.transform(X_train)\n",
    "X_test_scaled_mlp = scaler_mlp_torch.transform(X_test)\n",
    "\n",
    "# CatBoost - Escalonamento com o scaler específico para CatBoost\n",
    "X_train_scaled_catboost = scaler_catboost.transform(X_train)\n",
    "X_test_scaled_catboost = scaler_catboost.transform(X_test)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 1. XGBoost\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "# Conjunto de treino\n",
    "# Previsões no conjunto de treino\n",
    "y_pred_prob_xgb_ensemble_train = xgb_model.predict(xgb.DMatrix(X_train_scaled_xgb))\n",
    "\n",
    "# Conjunto de teste\n",
    "# Fazer previsões (probabilidades)\n",
    "y_pred_prob_xgb_ensemble_test = xgb_model.predict(xgb.DMatrix(X_test_scaled_xgb))\n",
    "\n",
    "# Converter para classe binária (usando threshold 0.5)\n",
    "xgb_y_pred_xgb_ensemble_test_ = (y_pred_prob_xgb_ensemble_test >= 0.5).astype(int)\n",
    "\n",
    "# Calcular as métricas\n",
    "xgb_ensemble_accuracy = accuracy_score(y_test, xgb_y_pred_xgb_ensemble_test_)\n",
    "xgb_ensemble_precision = precision_score(y_test, xgb_y_pred_xgb_ensemble_test_)\n",
    "xgb_ensemble_recall = recall_score(y_test, xgb_y_pred_xgb_ensemble_test_)\n",
    "xgb_ensemble_f1 = f1_score(y_test, xgb_y_pred_xgb_ensemble_test_)\n",
    "xgb_ensemble_auc_roc = roc_auc_score(y_test, y_pred_prob_xgb_ensemble_test)  # Correção aqui\n",
    "xgb_ensemble_mcc = matthews_corrcoef(y_test, xgb_y_pred_xgb_ensemble_test_)\n",
    "xgb_ensemble_kappa = cohen_kappa_score(y_test, xgb_y_pred_xgb_ensemble_test_)\n",
    "xgb_ensemble_balanced_acc = balanced_accuracy_score(y_test, xgb_y_pred_xgb_ensemble_test_)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 2. MLP (Torch)\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "# Normalizar os dados\n",
    "X_train_scaled = scaler_mlp_torch.transform(X_train)\n",
    "X_test_scaled = scaler_mlp_torch.transform(X_test)\n",
    "\n",
    "# Converter para tensor do PyTorch\n",
    "X_train_tensor = torch.tensor(X_train_scaled, dtype=torch.float32).to(device)\n",
    "X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).to(device)\n",
    "\n",
    "# Criar a instância do modelo com os hiperparâmetros corretos\n",
    "input_size = X_test.shape[1]\n",
    "model_mlp_torch = MLP(input_size, hidden_layer_sizes, activation, dropout_rate)\n",
    "\n",
    "# Carregar o modelo salvo\n",
    "model_mlp_torch = torch.load(r\"C:\\Users\\jgeov\\OneDrive\\Documentos\\GitHub\\Ciencia_de_dados-1\\Churn_predict\\MLP-Pytorch\\best_model_inteiro.pth\", map_location=device)\n",
    "model_mlp_torch.to(device)\n",
    "model_mlp_torch.eval()\n",
    "\n",
    "# Fazer previsões para os dados de teste\n",
    "with torch.no_grad():\n",
    "    # Aplicar a função sigmoide para garantir que as probabilidades estão no intervalo [0, 1]\n",
    "    y_pred_proba_mlp_ensemble_test = torch.sigmoid(model_mlp_torch(X_test_tensor)).cpu().numpy().flatten()\n",
    "\n",
    "# Converter probabilidades para rótulos binários (0 ou 1) no conjunto de teste\n",
    "y_pred_mlp_ensemble_test_ = (y_pred_proba_mlp_ensemble_test >= 0.5).astype(int)\n",
    "\n",
    "# Fazer previsões para os dados de treino\n",
    "with torch.no_grad():\n",
    "    # Aplicar a função sigmoide para garantir que as probabilidades estão no intervalo [0, 1]\n",
    "    y_pred_proba_mlp_ensemble_train = torch.sigmoid(model_mlp_torch(X_train_tensor)).cpu().numpy().flatten()\n",
    "\n",
    "# Converter probabilidades para rótulos binários (0 ou 1) no conjunto de treino\n",
    "y_pred_mlp_ensemble_train_ = (y_pred_proba_mlp_ensemble_train >= 0.5).astype(int)\n",
    "\n",
    "# Agora, temos as probabilidades e as classes para treino e teste\n",
    "\n",
    "# Calcular as métricas\n",
    "mlp_ensemble_accuracy = accuracy_score(y_test, y_pred_mlp_ensemble_test_)\n",
    "mlp_ensemble_precision = precision_score(y_test, y_pred_mlp_ensemble_test_)\n",
    "mlp_ensemble_recall = recall_score(y_test, y_pred_mlp_ensemble_test_)\n",
    "mlp_ensemble_f1 = f1_score(y_test, y_pred_mlp_ensemble_test_)\n",
    "mlp_ensemble_auc_roc = roc_auc_score(y_test, y_pred_proba_mlp_ensemble_test)  # AUC-ROC agora usando as probabilidades (não as classes)\n",
    "mlp_ensemble_mcc = matthews_corrcoef(y_test, y_pred_mlp_ensemble_test_)\n",
    "mlp_ensemble_kappa = cohen_kappa_score(y_test, y_pred_mlp_ensemble_test_)\n",
    "mlp_ensemble_balanced_acc = balanced_accuracy_score(y_test, y_pred_mlp_ensemble_test_)\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# 3. CatBoost\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "\n",
    "# Previsões e métricas treino \n",
    "# Previsões no conjunto de treino\n",
    "catboost_y_pred_proba_ensemble_train = model_catboost.predict_proba(X_train_scaled_catboost)[:, 1]\n",
    "catboost_y_pred_ensemble_train_ = (catboost_y_pred_proba_ensemble_train >= 0.5).astype(int)\n",
    "\n",
    "# Previsões e métricas teste \n",
    "catboost_y_pred_proba_ensemble_teste = model_catboost.predict_proba(X_test_scaled_catboost)[:, 1]\n",
    "catboost_y_pred_ensemble_teste_ = (catboost_y_pred_proba_ensemble_teste >= 0.5).astype(int)\n",
    "\n",
    "# Calcular as métricas\n",
    "catboost_ensemble_accuracy = accuracy_score(y_test, catboost_y_pred_ensemble_teste_)\n",
    "catboost_ensemble_precision = precision_score(y_test, catboost_y_pred_ensemble_teste_)\n",
    "catboost_ensemble_recall = recall_score(y_test, catboost_y_pred_ensemble_teste_)\n",
    "catboost_ensemble_f1 = f1_score(y_test, catboost_y_pred_ensemble_teste_)\n",
    "catboost_ensemble_auc_roc = roc_auc_score(y_test, catboost_y_pred_proba_ensemble_teste)  # Correção aqui\n",
    "catboost_ensemble_mcc = matthews_corrcoef(y_test, catboost_y_pred_ensemble_teste_)\n",
    "catboost_ensemble_kappa = cohen_kappa_score(y_test, catboost_y_pred_ensemble_teste_)\n",
    "catboost_ensemble_balanced_acc = balanced_accuracy_score(y_test, catboost_y_pred_ensemble_teste_)\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Exibir as métricas para os três modelos\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Dados das métricas de cada modelo\n",
    "data = {\n",
    "    'Métrica': ['Acurácia', 'Precisão', 'Recall', 'F1-Score', 'AUC-ROC', 'MCC', 'Kappa de Cohen', 'Acurácia Balanceada'],\n",
    "    'XGBoost': [xgb_ensemble_accuracy, xgb_ensemble_precision, xgb_ensemble_recall, xgb_ensemble_f1, xgb_ensemble_auc_roc, \n",
    "                xgb_ensemble_mcc, xgb_ensemble_kappa, xgb_ensemble_balanced_acc],\n",
    "    'MLP (Torch)': [mlp_ensemble_accuracy, mlp_ensemble_precision, mlp_ensemble_recall, mlp_ensemble_f1, mlp_ensemble_auc_roc, \n",
    "                    mlp_ensemble_mcc, mlp_ensemble_kappa, mlp_ensemble_balanced_acc],\n",
    "    'CatBoost': [catboost_ensemble_accuracy, catboost_ensemble_precision, catboost_ensemble_recall, catboost_ensemble_f1, catboost_ensemble_auc_roc, \n",
    "                 catboost_ensemble_mcc, catboost_ensemble_kappa, catboost_ensemble_balanced_acc]\n",
    "}\n",
    "\n",
    "# Criando o DataFrame\n",
    "metrics_df = pd.DataFrame(data)\n",
    "\n",
    "# Plotando a tabela com as métricas\n",
    "fig, ax = plt.subplots(figsize=(10, 3))  # Aumentei a largura para caber melhor os dados\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "table = ax.table(cellText=metrics_df.values, colLabels=metrics_df.columns, cellLoc='center', loc='center', colColours=[\"lightblue\"]*4)\n",
    "\n",
    "# Ajustando os parâmetros da tabela\n",
    "table.auto_set_font_size(False)  # Não usar o tamanho automático da fonte\n",
    "table.set_fontsize(10)  # Definindo o tamanho da fonte para ser menor e caber melhor\n",
    "table.scale(1.2, 1.2)  # Aumentando o tamanho da tabela para ocupar mais espaço\n",
    "\n",
    "# Ajustando o layout para remover qualquer espaçamento extra\n",
    "plt.subplots_adjust(left=0.05, right=0.95, top=0.9, bottom=0.1)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Plotar as Curvas ROC AUC dos três modelos, incluindo treino\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "# ROC Curve - XGBoost (Treinamento)\n",
    "fpr_xgb_train, tpr_xgb_train, _ = roc_curve(y_train, xgb_model.predict(xgb.DMatrix(X_train_scaled_xgb)))\n",
    "plt.plot(fpr_xgb_train, tpr_xgb_train, label=f\"XGBoost Treinamento (AUC = {roc_auc_score(y_train, xgb_model.predict(xgb.DMatrix(X_train_scaled_xgb))):.4f})\", linestyle='--')\n",
    "\n",
    "# ROC Curve - XGBoost (teste)\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_test, y_pred_prob_xgb_ensemble_test)\n",
    "plt.plot(fpr_xgb, tpr_xgb, label=f\"XGBoost Teste (AUC = {xgb_ensemble_auc_roc:.4f})\")\n",
    "\n",
    "\n",
    "\n",
    "# ROC Curve - MLP (PyTorch)  (Treinamento)\n",
    "fpr_mlp_train, tpr_mlp_train, _ = roc_curve(y_train, model_mlp_torch(torch.tensor(X_train_scaled_mlp, dtype=torch.float32).to(device)).cpu().detach().numpy())\n",
    "plt.plot(fpr_mlp_train, tpr_mlp_train, label=f\"MLP (PyTorch) Treinamento (AUC = {roc_auc_score(y_train, model_mlp_torch(torch.tensor(X_train_scaled_mlp, dtype=torch.float32).to(device)).cpu().detach().numpy()):.4f})\", linestyle='--')\n",
    "\n",
    "# ROC Curve - MLP (PyTorch) (teste)\n",
    "fpr_mlp, tpr_mlp, _ = roc_curve(y_test, y_pred_proba_mlp_ensemble_test)\n",
    "plt.plot(fpr_mlp, tpr_mlp, label=f\"MLP (PyTorch) Teste (AUC = {mlp_ensemble_auc_roc:.4f})\")\n",
    "\n",
    "\n",
    "\n",
    "# ROC Curve - CatBoost - (Treinamento)\n",
    "fpr_catboost_train, tpr_catboost_train, _ = roc_curve(y_train, model_catboost.predict_proba(X_train_scaled_catboost)[:, 1])\n",
    "plt.plot(fpr_catboost_train, tpr_catboost_train, label=f\"CatBoost Treinamento (AUC = {roc_auc_score(y_train, model_catboost.predict_proba(X_train_scaled_catboost)[:, 1]):.4f})\", linestyle='--')\n",
    "\n",
    "# ROC Curve - CatBoost (teste)\n",
    "fpr_catboost, tpr_catboost, _ = roc_curve(y_test, catboost_y_pred_proba_ensemble_teste)\n",
    "plt.plot(fpr_catboost, tpr_catboost, label=f\"CatBoost Teste (AUC = {catboost_ensemble_auc_roc:.4f})\")\n",
    "\n",
    "\n",
    "\n",
    "# Linha de Chance\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")  # Linha diagonal\n",
    "\n",
    "plt.xlabel(\"Taxa de Falsos Positivos\")\n",
    "plt.ylabel(\"Taxa de Verdadeiros Positivos\")\n",
    "plt.title(\"Curvas ROC AUC (Teste e Treinamento)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# ----------------------------------------------------------\n",
    "# Plotar as Matrizes de Confusão dos três modelos em Subplots\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Matriz de Confusão - XGBoost nos dados de teste\n",
    "xgb_cm = confusion_matrix(y_test, xgb_y_pred_xgb_ensemble_test_)\n",
    "sns.heatmap(xgb_cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=axes[0], \n",
    "            xticklabels=['Classe 0', 'Classe 1'], yticklabels=['Classe 0', 'Classe 1'])\n",
    "axes[0].set_title(\"Matriz de Confusão - XGBoost  (TESTE)\")\n",
    "axes[0].set_xlabel('Previsões')\n",
    "axes[0].set_ylabel('Valores Reais')\n",
    "\n",
    "# Matriz de Confusão - MLP nos dados de teste\n",
    "mlp_cm = confusion_matrix(y_test, y_pred_mlp_ensemble_test_)\n",
    "sns.heatmap(mlp_cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=axes[1], \n",
    "            xticklabels=['Classe 0', 'Classe 1'], yticklabels=['Classe 0', 'Classe 1'])\n",
    "axes[1].set_title(\"Matriz de Confusão - MLP (PyTorch)  (TESTE)\")\n",
    "axes[1].set_xlabel('Previsões')\n",
    "axes[1].set_ylabel('Valores Reais')\n",
    "\n",
    "# Matriz de Confusão - CatBoost nos dados de teste \n",
    "catboost_cm = confusion_matrix(y_test, catboost_y_pred_ensemble_teste_)\n",
    "sns.heatmap(catboost_cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=axes[2], \n",
    "            xticklabels=['Classe 0', 'Classe 1'], yticklabels=['Classe 0', 'Classe 1'])\n",
    "axes[2].set_title(\"Matriz de Confusão - CatBoost  (TESTE)\")\n",
    "axes[2].set_xlabel('Previsões')\n",
    "axes[2].set_ylabel('Valores Reais')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef, cohen_kappa_score, balanced_accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Gerar previsões dos 3 modelos (predicoes separadas)\n",
    "# ------------------------------------------------------\n",
    "\n",
    "# Criar DataFrames de treino e teste para as previsões\n",
    "df_predicoes_train = pd.DataFrame({\n",
    "    'XGBoost_Prob': y_pred_prob_xgb_ensemble_train,\n",
    "    'MLP_Torch_Prob': y_pred_proba_mlp_ensemble_train,\n",
    "    'CatBoost_Prob': catboost_y_pred_proba_ensemble_train\n",
    "}, index=X_train.index)  # Mantendo o mesmo índice do X_train\n",
    "\n",
    "df_predicoes_test = pd.DataFrame({\n",
    "    'XGBoost_Prob': y_pred_prob_xgb_ensemble_test,\n",
    "    'MLP_Torch_Prob': y_pred_proba_mlp_ensemble_test,\n",
    "    'CatBoost_Prob': catboost_y_pred_proba_ensemble_teste\n",
    "}, index=X_test.index)  # Mantendo o mesmo índice do X_test\n",
    "\n",
    "# Concatenar com os datasets originais\n",
    "X_train_stacking = pd.concat([X_train, df_predicoes_train], axis=1)\n",
    "X_test_stacking = pd.concat([X_test, df_predicoes_test], axis=1)\n",
    "\n",
    "# Exibir as primeiras linhas para conferir se as probs estao vindo certo\n",
    "print(X_train_stacking.head())\n",
    "print(X_test_stacking.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------------------------------------------------------\n",
    "# Gerar previsões dos 3 modelos (medias das probabilidades)\n",
    "# ------------------------------------------------------\n",
    "\n",
    "# Criar DataFrames de treino e teste para as previsões individuais\n",
    "#df_predicoes_train = pd.DataFrame({\n",
    "#    'XGBoost_Prob': y_pred_prob_xgb_ensemble_train,\n",
    "#    'MLP_Torch_Prob': y_pred_proba_mlp_ensemble_train,\n",
    "#    'CatBoost_Prob': catboost_y_pred_proba_ensemble_train\n",
    "#}, index=X_train.index)  # Mantendo o mesmo índice do X_train\n",
    "\n",
    "#df_predicoes_test = pd.DataFrame({\n",
    "#    'XGBoost_Prob': y_pred_prob_xgb_ensemble_test,\n",
    "#    'MLP_Torch_Prob': y_pred_proba_mlp_ensemble_test,\n",
    "#    'CatBoost_Prob': catboost_y_pred_proba_ensemble_teste\n",
    "#}, index=X_test.index)  # Mantendo o mesmo índice do X_test\n",
    "\n",
    "#print(df_predicoes_train.head())\n",
    "#print(df_predicoes_test.head())\n",
    "\n",
    "# Calcular a média das probabilidades para treino e teste (mantendo apenas a média)\n",
    "#df_predicoes_train_media = pd.DataFrame({\n",
    "#    'Media_Prob': df_predicoes_train.mean(axis=1)\n",
    "#}, index=X_train.index)  # Mantendo o mesmo índice do X_train\n",
    "\n",
    "#df_predicoes_test_media = pd.DataFrame({\n",
    "#    'Media_Prob': df_predicoes_test.mean(axis=1)\n",
    "#}, index=X_test.index)  # Mantendo o mesmo índice do X_test\n",
    "\n",
    "# Concatenar apenas as médias com os datasets originais\n",
    "#X_train_stacking = pd.concat([X_train, df_predicoes_train_media], axis=1)\n",
    "#X_test_stacking = pd.concat([X_test, df_predicoes_test_media], axis=1)\n",
    "\n",
    "\n",
    "# Exibir as primeiras linhas para conferir se as probs estao vindo certo\n",
    "#print('---------------------------------------------------------------------------' ) #so pra separar os prints\n",
    "#print(X_train_stacking.head())\n",
    "#print(X_test_stacking.head())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#testando modelos para serrem metamodels(aqui so anota mesmo)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Criar o modelo de regressão logística # BOM MAS NEM TANTO\n",
    "#meta_model = LogisticRegression()\n",
    "\n",
    "# Criar o modelo XGBoost # Razoavel \n",
    "#meta_model = XGBClassifier(random_state=42) \n",
    "\n",
    "\n",
    "# Criar o modelo LightGBM# bom mas insatisfatorio \n",
    "#meta_model = LGBMClassifier(random_state=42)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AQUI PRECISA ACHAR UMA FORMA DE APLICAR O SCALE_POS_WEIGHT PARA O mlp kERAS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificando balanceametno final (morrer de certeza)\n",
    "print(round(y_train.value_counts(normalize=True)*100,1))\n",
    "#continuam naturalmente desbalanceadas \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Calcular o peso ideal para scale_pos_weight quando esta desbalanceado: pode ser pelo calculo de \n",
    "# razão inversa das proporções das classes (boa pratica pra dar um norte de onde comecar a explorar o hiperparametro scale_pos_weight):\n",
    "\n",
    "pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "pos_weight\n",
    " \n",
    "# isso significa que a classe 0 (Negativa) é 3.86 vezes maior que a positiva (1)\n",
    "\n",
    "# o estudo de scale_pos_weight melhor foi necessario por o modelo estava propenso a definir a maioria dos casos como negativo por conta dos baixos valores de probabilidade (muito pelo threshold tbm). \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# teste de Shapiro-Wilk nos dados de treinamento \n",
    "* Padronização vs Normalização:\n",
    "\n",
    "    * Padronização (StandardScaler):\n",
    "\n",
    "            Utilizada quando os dados possuem distribuições com outliers ou grandes variações.\n",
    "            Transformação para média 0 e desvio padrão 1, preservando a distribuição dos dados.\n",
    "\n",
    "    * Normalização (MinMaxScaler):\n",
    "\n",
    "            Recomendável quando os dados têm uma faixa limitada de valores ou distribuição assimétrica.\n",
    "            Útil para modelos com funções de ativação como sigmoide ou tanh que exigem entradas em um intervalo específico.\n",
    "            Transforma os dados para um intervalo, geralmente [0, 1], garantindo que todas as variáveis fiquem na mesma escala.\n",
    "\n",
    "    * Conclusão do este de SHAPIRO: \n",
    "    \n",
    "            Dados não apresentam normalidade, a normalização (MinMaxScaler) foi a técnica escolhida. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import shapiro\n",
    "\n",
    "# Definindo o número de colunas para os subplots\n",
    "num_cols = 3  # O número de colunas de subplots\n",
    "num_vars = len(X_train_stacking.select_dtypes(include=['float32','float64', 'int64']).columns)  # Número de variáveis\n",
    "num_rows = (num_vars // num_cols) + (num_vars % num_cols > 0)  # Calculando o número de linhas de subplots\n",
    "\n",
    "# Ajustando o tamanho dos gráficos (largura, altura) com base no número de subgráficos\n",
    "fig_width = 5 * num_cols  # Largura proporcional ao número de colunas\n",
    "fig_height = 5 * num_rows  # Altura proporcional ao número de linhas\n",
    "\n",
    "# Criando os subplots com o tamanho ajustado\n",
    "fig, axes = plt.subplots(num_rows, num_cols, figsize=(fig_width, fig_height))\n",
    "axes = axes.flatten()  # Para garantir que podemos indexar de forma unificada\n",
    "\n",
    "# Iterando pelas variáveis numéricas\n",
    "for i, column in enumerate(X_train_stacking.select_dtypes(include=['float32','float64', 'int64']).columns):\n",
    "    # Teste de Shapiro-Wilk\n",
    "    stat, p = shapiro(X_train_stacking[column])\n",
    "\n",
    "    # Plotando o histograma e KDE\n",
    "    sns.histplot(X_train_stacking[column], kde=True, ax=axes[i], color='skyblue', stat='density')\n",
    "    axes[i].set_title(f\"{column} | p-value = {p:.4f}\")\n",
    "    axes[i].set_xlabel(column)\n",
    "    axes[i].set_ylabel('Densidade')\n",
    "\n",
    "    # Adicionando texto sobre o p-valor\n",
    "    if p > 0.05:\n",
    "        axes[i].text(0.05, 0.95, f\"Normal: p > 0.05\", transform=axes[i].transAxes, fontsize=12, color='green')\n",
    "    else:\n",
    "        axes[i].text(0.05, 0.95, f\"Não normal: p < 0.05\", transform=axes[i].transAxes, fontsize=12, color='red')\n",
    "\n",
    "# Ajustando layout\n",
    "plt.tight_layout(pad=0.5)  # Ajustando o espaçamento entre os subgráficos\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, matthews_corrcoef, cohen_kappa_score, balanced_accuracy_score\n",
    "import numpy as np\n",
    "import optuna\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Verificar se há GPU disponível\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if gpus:\n",
    "    print(\"GPU disponível:\", gpus)\n",
    "else:\n",
    "    print(\"GPU não disponível.\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Definindo a barra de progresso\n",
    "n_trials_ = 150\n",
    "threshold= 0.5\n",
    "progress_bar = tqdm(total=n_trials_, desc=\"Otimização em andamento\", unit=\"trial\")\n",
    "\n",
    "# Definindo os pesos das métricas para otimização\n",
    "weights_skf = {\n",
    "    'Accuracy': 0.00,\n",
    "    'f1': 0.10,\n",
    "    'precision': 0.10,\n",
    "    'recall': 0.60,\n",
    "    'auc': 0.10,\n",
    "    'balanced_acc': 0.10,\n",
    "    'mcc': 0.00\n",
    "}\n",
    "\n",
    "\n",
    "scaler = MinMaxScaler() # inicia normalizador\n",
    "\n",
    "\n",
    "smote = BorderlineSMOTE(sampling_strategy='auto', random_state=42) # Inicia do BorderlineSMOTE\n",
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    global progress_bar\n",
    "    global threshold \n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.0001, 0.01, log=True)\n",
    "    n_hidden_units = trial.suggest_int('n_hidden_units', 128, 256)\n",
    "    n_layers = trial.suggest_int('n_layers', 2, 4)\n",
    "    dropout_rate = trial.suggest_float('dropout_rate', 0.4, 0.7)\n",
    "    batch_size = trial.suggest_categorical('batch_size', [128, 256])\n",
    "    epochs = trial.suggest_int('epochs', 30, 80)\n",
    "    \n",
    "    activation_function = trial.suggest_categorical('activation_function', ['relu', 'tanh'])\n",
    "    optimizer = trial.suggest_categorical('optimizer', ['adam', 'sgd', 'rmsprop', 'nadam'])\n",
    "\n",
    "    weight_decay = trial.suggest_float('weight_decay', 0.0001, 0.1, log=True)\n",
    "    l2_regularization = trial.suggest_float('l2_regularization', 0.001, 0.1, log=True)\n",
    "    momentum = trial.suggest_float('momentum', 0.4, 0.95) if optimizer == 'sgd' else 0.0\n",
    "\n",
    "    verbose = 0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Criando o modelo MLP\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.InputLayer(input_shape=(X_train_stacking.shape[1],)))\n",
    "\n",
    "    # Definindo o inicializador de pesos com base na função de ativação\n",
    "    for _ in range(n_layers):\n",
    "        if activation_function == 'relu':\n",
    "            initializer = 'he_normal'\n",
    "        elif activation_function == 'tanh':\n",
    "            initializer = 'glorot_uniform'\n",
    "        else:\n",
    "            initializer = 'glorot_uniform'  # Opção padrão caso queira adicionar outras ativations\n",
    "\n",
    "        model.add(layers.Dense(n_hidden_units, activation=activation_function, \n",
    "                                kernel_initializer=initializer,  # Usando o inicializador com base na função de ativação\n",
    "                                kernel_regularizer=keras.regularizers.l2(l2_regularization)))\n",
    "        model.add(layers.Dropout(dropout_rate))\n",
    "\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))  # Camada de saída\n",
    "\n",
    "\n",
    "    # Compilando o modelo\n",
    "    if optimizer == 'adam':\n",
    "        opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    elif optimizer == 'sgd':\n",
    "        opt = keras.optimizers.SGD(learning_rate=learning_rate, momentum=momentum)\n",
    "    elif optimizer == 'nadam':\n",
    "        opt = keras.optimizers.Nadam(learning_rate=learning_rate)  # com a taxa de aprendizado\n",
    "    else:\n",
    "        opt = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=0)\n",
    "\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['AUC', 'accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # Realizando a validação cruzada estratificada\n",
    "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "    global weights_skf\n",
    "    weighted_scores = []\n",
    "    auc_roc_list, accuracy_list, precision_list, recall_list, f1_list, mcc_list, kappa_list, balanced_acc_list = [], [], [], [], [], [], [], []\n",
    "\n",
    "    for train_idx, val_idx in skf.split(X_train_stacking, y_train):\n",
    "        X_train_fold, X_val_fold = X_train_stacking.iloc[train_idx], X_train_stacking.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        # Normalizando os dados de treino (sem vazamento de dados)\n",
    "        X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n",
    "        X_val_fold_scaled = scaler.transform(X_val_fold)  # Aplica a transformação nos dados de validação\n",
    "\n",
    "        # Aplicando o BorderlineSMOTE para balancear a classe minoritária no treino\n",
    "        X_train_fold_scaled, y_train_fold = smote.fit_resample(X_train_fold_scaled, y_train_fold)\n",
    "\n",
    "        # Treinando o modelo\n",
    "        model.fit(X_train_fold_scaled, y_train_fold, epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "\n",
    "        # Prevendo as probabilidades da classe 1\n",
    "        y_pred_prob = model.predict(X_val_fold_scaled, verbose=verbose).flatten()\n",
    "        # Garantir que não há NaN nas previsões\n",
    "        y_pred_prob = np.nan_to_num(y_pred_prob)\n",
    "\n",
    "        y_pred = (y_pred_prob >= threshold).astype(int)\n",
    "\n",
    "        auc_roc_list.append(roc_auc_score(y_val_fold, y_pred_prob))\n",
    "        accuracy_list.append(accuracy_score(y_val_fold, y_pred))\n",
    "        precision_list.append(precision_score(y_val_fold, y_pred))\n",
    "        recall_list.append(recall_score(y_val_fold, y_pred))\n",
    "        f1_list.append(f1_score(y_val_fold, y_pred))\n",
    "        mcc_list.append(matthews_corrcoef(y_val_fold, y_pred))\n",
    "        kappa_list.append(cohen_kappa_score(y_val_fold, y_pred))\n",
    "        balanced_acc_list.append(balanced_accuracy_score(y_val_fold, y_pred))\n",
    "\n",
    "        # Métricas para otimizar\n",
    "        metrics_mean = {\n",
    "            \"AUC-ROC\": np.mean(auc_roc_list),\n",
    "            \"Accuracy\": np.mean(accuracy_list),\n",
    "            \"Precision\": np.mean(precision_list),\n",
    "            \"Recall\": np.mean(recall_list),\n",
    "            \"F1-Score\": np.mean(f1_list),\n",
    "            \"MCC\": np.mean(mcc_list),\n",
    "            \"Kappa\": np.mean(kappa_list),\n",
    "            \"Balanced Accuracy\": np.mean(balanced_acc_list),\n",
    "        }\n",
    "\n",
    "        weighted_score = (\n",
    "            weights_skf['f1'] * metrics_mean[\"F1-Score\"] +\n",
    "            weights_skf['precision'] * metrics_mean[\"Precision\"] +\n",
    "            weights_skf['recall'] * metrics_mean[\"Recall\"] +\n",
    "            weights_skf['auc'] * metrics_mean[\"AUC-ROC\"] +\n",
    "            weights_skf['balanced_acc'] * metrics_mean[\"Balanced Accuracy\"] +\n",
    "            weights_skf['Accuracy'] * metrics_mean[\"Accuracy\"] +\n",
    "            weights_skf['mcc'] * metrics_mean[\"MCC\"]\n",
    "        )\n",
    "        weighted_scores.append(weighted_score)\n",
    "\n",
    "    # Imprimir o resumo das métricas\n",
    "    print(\"📊 MÉTRICAS DOS FOLDS\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"{'Métrica':<25} {'Valor final'}\")\n",
    "    print(\"-\"*60)\n",
    "\n",
    "    for metric, value in metrics_mean.items():\n",
    "        print(f\"{metric:<25} {value:.4f}\")\n",
    "\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    progress_bar.update(1)\n",
    "    return np.mean(weighted_scores)\n",
    "\n",
    "# Otimização com Optuna\n",
    "\n",
    "sampler_ = optuna.samplers.TPESampler(n_startup_trials=10, \n",
    "                                      n_ei_candidates=50, \n",
    "                                      group=True,seed=42,\n",
    "                                      multivariate=True)\n",
    "\n",
    "study = optuna.create_study(direction='maximize', sampler=sampler_, pruner=optuna.pruners.PatientPruner(optuna.pruners.MedianPruner(), patience=15))\n",
    "study.optimize(objective, n_trials=n_trials_)  # Certifique-se de que n_trials_ está bem definido\n",
    "\n",
    "\n",
    "best_params = study.best_params\n",
    "\n",
    "# Melhores hiperparâmetros\n",
    "print(\"📊 MELHORES HIPERPARÂMETROS ENCONTRADOS\")\n",
    "print(\"═\" * 60)\n",
    "for param, value in best_params.items():\n",
    "    print(f\"{param:<25}{value:<15}\")\n",
    "print(\"═\" * 60)\n",
    "\n",
    "\n",
    "### TREINAMETNO FINAL \n",
    "\n",
    "# Criando modelo final com os melhores parâmetros obtidos pelo Optuna \n",
    "final_model = keras.Sequential()\n",
    "\n",
    "# Adicionando a camada de entrada\n",
    "final_model.add(layers.InputLayer(input_shape=(X_train_stacking.shape[1],)))\n",
    "\n",
    "# Inicializador de pesos para a camada final (sigmoid)\n",
    "weight_initializer_final = 'glorot_uniform'  # Usando Glorot Uniform para a camada de saída sigmoid\n",
    "\n",
    "# Inicializador de pesos para as camadas ocultas\n",
    "if best_params['activation_function'] == 'relu':\n",
    "    weight_initializer_hidden = 'he_normal'  # He Normal para ReLU\n",
    "elif best_params['activation_function'] == 'tanh':\n",
    "    weight_initializer_hidden = 'glorot_uniform'  # Xavier ou Glorot Uniform para Tanh\n",
    "\n",
    "# Adicionando as camadas ocultas com os melhores parâmetros\n",
    "for _ in range(best_params['n_layers']):\n",
    "    final_model.add(layers.Dense(best_params['n_hidden_units'], \n",
    "                                 activation=best_params['activation_function'],\n",
    "                                 kernel_initializer=weight_initializer_hidden,\n",
    "                                 kernel_regularizer=keras.regularizers.l2(best_params['l2_regularization'] + best_params['weight_decay'])))  # Aplicando weight_decay aqui\n",
    "    final_model.add(layers.Dropout(best_params['dropout_rate']))  # Dropout após cada camada densa\n",
    "\n",
    "# Camada de saída\n",
    "final_model.add(layers.Dense(1, activation='sigmoid', kernel_initializer=weight_initializer_final))  # Saída binária\n",
    "\n",
    "# Escolhendo o otimizador com base nos melhores parâmetros\n",
    "if best_params['optimizer'] == 'adam':\n",
    "    opt = keras.optimizers.Adam(learning_rate=best_params['learning_rate'])\n",
    "elif best_params['optimizer'] == 'sgd':\n",
    "    opt = keras.optimizers.SGD(learning_rate=best_params['learning_rate'], momentum=best_params['momentum'])\n",
    "else:\n",
    "    opt = keras.optimizers.RMSprop(learning_rate=best_params['learning_rate'])\n",
    "\n",
    "# Compilando o modelo\n",
    "final_model.compile(optimizer=opt, \n",
    "                    loss='binary_crossentropy', \n",
    "                    metrics=['AUC', 'accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###### TREINANDO MODELO FINAL\n",
    "\n",
    "\n",
    "# Normalizando os dados de treinamento final\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_stacking)\n",
    "\n",
    "# Aplicando o BorderlineSMOTE no treinamento final para balancear as classes\n",
    "smote = BorderlineSMOTE(sampling_strategy='auto', random_state=42)\n",
    "X_train_scaled, y_train = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Criando o callback EarlyStopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Monitorando a perda de validação\n",
    "    patience=15,  # Se não houver melhoria por 15 épocas, o treinamento será interrompido\n",
    "    restore_best_weights=True,  # Restaurando os melhores pesos do modelo\n",
    "    verbose=0  # MENSAGENS \n",
    ")\n",
    "\n",
    "# Treinando o modelo final com validação e capturando o histórico\n",
    "history = final_model.fit(\n",
    "    X_train_scaled, \n",
    "    y_train,\n",
    "    epochs=best_params['epochs'],\n",
    "    batch_size=best_params['batch_size'],\n",
    "    verbose=0,  # Omitindo os logs a cada época\n",
    "    validation_split=0.2,  # Usando 20% dos dados para validação\n",
    "    callbacks=[early_stopping]  # Passando o callback de EarlyStopping\n",
    ")\n",
    "\n",
    "# Extraindo os valores da perda do histórico de treinamento\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(1, len(loss) + 1)\n",
    "\n",
    "# Criando o gráfico da perda por época\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(epochs_range, loss, label='Loss - Treinamento', color='blue')\n",
    "plt.plot(epochs_range, val_loss, label='Loss - Validação', color='red', linestyle='dashed')\n",
    "\n",
    "# Configurando os rótulos e título\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Perda (Loss)')\n",
    "plt.title('Evolução da Perda Durante o Treinamento')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Exibindo o gráfico\n",
    "plt.show()\n",
    "########################################### ALTERADO ATE AQUI (TESTANTO)\n",
    "\n",
    "\n",
    "# Normalizando os dados de teste\n",
    "X_test_scaled = scaler.transform(X_test_stacking)\n",
    "\n",
    "# Fazendo predições com o modelo final\n",
    "y_pred_final_prob = final_model.predict(X_test_scaled,verbose=0).flatten()  # Obtendo as probabilidades\n",
    "\n",
    "# Definindo o limiar para determinar a classe final\n",
    "y_pred_final = (y_pred_final_prob >= threshold).astype(int)  # O limiar padrão é 0.5, mas pode ser ajustado\n",
    "\n",
    "\n",
    "\n",
    "# Cálculo das métricas\n",
    "accuracy = accuracy_score(y_test, y_pred_final)\n",
    "precision = precision_score(y_test, y_pred_final)\n",
    "recall = recall_score(y_test, y_pred_final)\n",
    "f1 = f1_score(y_test, y_pred_final)\n",
    "auc_roc = roc_auc_score(y_test, y_pred_final_prob)\n",
    "mcc = matthews_corrcoef(y_test, y_pred_final)\n",
    "kappa = cohen_kappa_score(y_test, y_pred_final)\n",
    "balanced_acc = balanced_accuracy_score(y_test, y_pred_final)\n",
    "gini = (2 * auc_roc - 1) * 100\n",
    "\n",
    "# Exibir as métricas finais\n",
    "print(\"📊 MÉTRICAS FINAIS - TESTE\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"{'Métrica':<25} {'Valor final'}\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Acurácia':<25} {accuracy:.4f}\")\n",
    "print(f\"{'Precisão':<25} {precision:.4f}\")\n",
    "print(f\"{'Recall':<25} {recall:.4f}\")\n",
    "print(f\"{'F1-Score':<25} {f1:.4f}\")\n",
    "print(f\"{'AUC-ROC':<25} {auc_roc:.4f}\")\n",
    "print(f\"{'MCC':<25} {mcc:.4f}\")\n",
    "print(f\"{'Kappa':<25} {kappa:.4f}\")\n",
    "print(f\"{'Acurácia Balanceada':<25} {balanced_acc:.4f}\")\n",
    "print(f\"{'Gini':<25} {gini:.4f}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Criando os gráficos\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Plot da Matriz de Confusão\n",
    "conf_matrix = confusion_matrix(y_test, y_pred_final)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Negativo', 'Positivo'], yticklabels=['Negativo', 'Positivo'],\n",
    "            cbar=False, ax=axes[0])\n",
    "axes[0].set_title('Matriz de Confusão (TESTE) - MLP')\n",
    "axes[0].set_xlabel('Previsão')\n",
    "axes[0].set_ylabel('Real')\n",
    "\n",
    "# Plot da curva ROC\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_pred_final_prob)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "axes[1].plot(fpr, tpr, color='darkorange', lw=2, label=f'AUC = {roc_auc:.2f}')\n",
    "axes[1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "axes[1].set_xlim([0.0, 1.0])\n",
    "axes[1].set_ylim([0.0, 1.05])\n",
    "axes[1].set_xlabel('Taxa de Falsos Positivos')\n",
    "axes[1].set_ylabel('Taxa de Verdadeiros Positivos')\n",
    "axes[1].set_title('Curva ROC (TESTE) - MLP')\n",
    "axes[1].legend(loc=\"lower right\")\n",
    "\n",
    "# Distribuição de probabilidades\n",
    "\n",
    "# classe positiva\n",
    "probs_pos = y_pred_final_prob  \n",
    "# classe negativa\n",
    "probs_neg = 1 - y_pred_final_prob\n",
    "\n",
    "# Plot classe positiva \n",
    "sns.kdeplot(probs_pos, color='blue', ax=axes[2], label='Classe Positiva', fill=True, alpha=0.6)\n",
    "\n",
    "# Plot classe negativa \n",
    "sns.kdeplot(probs_neg, color='red', ax=axes[2], label='Classe Negativa', fill=True, alpha=0.02, linewidth=0.30)\n",
    "\n",
    "# Ajustando o gráfico\n",
    "axes[2].set_title(\"Distribuição das Probabilidades para as Classes Positiva e Negativa (TESTE) - MLP Keras\")\n",
    "axes[2].set_xlabel(\"Probabilidade\")\n",
    "axes[2].set_ylabel(\"Densidade\")\n",
    "axes[2].legend()\n",
    "# setando eixo de probabilidades entre 0 e 1\n",
    "axes[2].set_xlim(0, 1)\n",
    "\n",
    "\n",
    "# Exibindo o gráfico\n",
    "plt.show()\n",
    "\n",
    "# Ajustando o layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#final_model.summary() #infos do modelo\n",
    "\n",
    "\n",
    "\n",
    "#NAO CONSGUI CONFIGURAR GPU, MUITA IMCOMPATIBILIDADE DE BIBLIOTECAS\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explicabilidade "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP Global\n",
    "\n",
    "* SHAP Global é uma técnica de explicabilidade que ajuda a entender a importância de cada variável (feature) nas predições do modelo de maneira global, ou seja, avaliando o impacto médio de cada feature ao longo de todas as instâncias do conjunto de dados.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Criação do explicador SHAP\n",
    "\n",
    "background_samples = shap.kmeans(X_train_scaled, 50)  # 100 clusters representativos\n",
    "\n",
    "explainer = shap.KernelExplainer(lambda x: final_model.predict(x, verbose=0), background_samples,n_jobs=-1 )\n",
    "\n",
    "\n",
    "# Calculando os valores SHAP para o conjunto de teste\n",
    "shap_values = explainer.shap_values(X_test_scaled)\n",
    "\n",
    "# Plotando o gráfico de importância global com o SHAP\n",
    "shap.summary_plot(shap_values[0], X_test_scaled, feature_names=[f\"Feature {i+1}\" for i in range(X_test_scaled.shape[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME (Local) \n",
    "\n",
    "* LIME (Local Interpretable Model-agnostic Explanations) é uma técnica de explicabilidade que busca interpretar predições de modelos de forma local, ou seja, explicar como o modelo chegou a uma decisão específica para uma instância de dado individual. \n",
    "\n",
    "* Ao contrário de métodos globais, como o SHAP, que explicam a importância das features em todas as predições, o LIME foca na explicação de uma única predição."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criando o explicador LIME para um modelo LightGBM\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "    training_data=X_test_stacking.values,  # Dados de treino\n",
    "    training_labels=y_test.values,         # Rótulos de treino\n",
    "    mode=\"classification\",                  # Tipo de problema (classificação)\n",
    "    class_names=[\"Negativo\", \"Positivo\"],   # Nomes das classes\n",
    "    feature_names=X_test_stacking.columns, # Nomes das features\n",
    "    discretize_continuous=True              # Discretizar variáveis contínuas\n",
    ")\n",
    "\n",
    "# Selecionando uma instância para explicar\n",
    "idx = 200  # Índice do exemplo/observação a ser explicado\n",
    "instance = X_test_stacking.iloc[idx].values.reshape(1, -1)\n",
    "\n",
    "# Função para obter probabilidades usando LightGBM (para classificação binária)\n",
    "def predict_proba_fn(x):\n",
    "    raw_preds = final_model.predict(x)  # Usando o método predict do LightGBM\n",
    "    # Convertendo as margens (logits) para probabilidades\n",
    "    probabilities = 1 / (1 + np.exp(-raw_preds))  # Sigmoide para classificação binária\n",
    "    return np.array([1 - probabilities, probabilities]).T  # Retorna a probabilidade para cada classe\n",
    "\n",
    "# Gerando explicação local com probabilidades de classe\n",
    "explanation = explainer.explain_instance(\n",
    "    instance.flatten(),  # Passando os valores da instância em um formato adequado\n",
    "    predict_proba_fn,     # Usando a função que retorna as probabilidades\n",
    "    num_features=40      # Número de características a serem mostradas\n",
    ")\n",
    "\n",
    "# Plotando a explicação\n",
    "fig = explanation.as_pyplot_figure()\n",
    "plt.show()\n",
    "\n",
    "# Gerando gráfico de importância das características (se necessário)\n",
    "# explanation.as_list()  # Para mostrar os valores, tipo print\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 3197960,
     "sourceId": 5550559,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
