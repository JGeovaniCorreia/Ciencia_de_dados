{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliotecas \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-03T00:57:15.289488Z",
     "iopub.status.busy": "2025-01-03T00:57:15.289220Z",
     "iopub.status.idle": "2025-01-03T00:57:16.388104Z",
     "shell.execute_reply": "2025-01-03T00:57:16.386874Z",
     "shell.execute_reply.started": "2025-01-03T00:57:15.289460Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt #graficos\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns #graficos\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score,  precision_score, recall_score, \n",
    "                             f1_score, accuracy_score, roc_curve, auc, make_scorer)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dicinário de Dados \n",
    "\n",
    "\n",
    "| **Variável**         | **Tipo**   | **Descrição**                                                                                                                                     |\n",
    "|-----------------------|------------|---------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| RowNumber            | int64      | Número do registro (linhas), sem efeito na construção de modelos.                                                                                |\n",
    "| CustomerId           | int64      | ID do cliente, sem efeito sobre o estudo.                                                                                                       |\n",
    "| Surname              | object     | Sobrenome do cliente, sem impacto na análise.                                                                                                   |\n",
    "| CreditScore          | int64      | Pontuação de crédito, pode indicar tendência de permanência de clientes com pontuação alta.                                                     |\n",
    "| Geography            | object     | Localização do cliente, pode influenciar a decisão de evasão.                                                                                   |\n",
    "| Gender               | object     | Gênero do cliente, possível influência na evasão.                                                                                               |\n",
    "| Age                  | int64      | Idade do cliente, clientes mais velhos tendem a permanecer.                                                                                     |\n",
    "| Tenure               | int64      | Anos que o cliente está no banco, clientes novos têm maior chance de evasão.                                                                    |\n",
    "| Balance              | float64    | Saldo na conta, pessoas com saldos altos são menos propensas a sair.                                                                            |\n",
    "| NumOfProducts        | int64      | Número de produtos adquiridos pelo cliente.                                                                                                    |\n",
    "| HasCrCard            | int64      | Indica se o cliente tem cartão de crédito, clientes com cartão são menos propensos à evasão.                                                    |\n",
    "| IsActiveMember       | int64      | Clientes ativos têm menor chance de evasão.                                                                                                    |\n",
    "| EstimatedSalary      | float64    | Salário estimado, clientes com salários mais altos tendem a permanecer.                                                                         |\n",
    "| Exited               | int64      | Indica se o cliente saiu ou não do banco, variável de predição (“churn”).                                                                       |\n",
    "| Complain             | int64      | Indica se o cliente fez reclamação.                                                                                                             |\n",
    "| Satisfaction Score   | int64      | Pontuação de satisfação com a resolução de reclamação.                                                                                          |\n",
    "| Card Type            | object     | Tipo de cartão que o cliente possui.                                                                                                            |\n",
    "| Points Earned        | int64      | Pontos ganhos pelo cliente.                                                                                                                     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-21T05:51:49.217695Z",
     "iopub.status.busy": "2024-12-21T05:51:49.217244Z",
     "iopub.status.idle": "2024-12-21T05:51:49.222777Z",
     "shell.execute_reply": "2024-12-21T05:51:49.221466Z",
     "shell.execute_reply.started": "2024-12-21T05:51:49.217658Z"
    }
   },
   "source": [
    "#  Análise Exploratória (EDA) & Data Prep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:57:16.389330Z",
     "iopub.status.busy": "2025-01-03T00:57:16.388900Z",
     "iopub.status.idle": "2025-01-03T00:57:16.431713Z",
     "shell.execute_reply": "2025-01-03T00:57:16.430562Z",
     "shell.execute_reply.started": "2025-01-03T00:57:16.389305Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# base de dados\n",
    "base_original = pd.read_csv('/kaggle/input/bank-customer-churn/Customer-Churn-Records.csv', sep=',')\n",
    "\n",
    "#configs para nao quebrar linhas no print do  df\n",
    "pd.set_option('display.expand_frame_repr', False) \n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#primeiras linhas \n",
    "base_original.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:57:16.434304Z",
     "iopub.status.busy": "2025-01-03T00:57:16.434073Z",
     "iopub.status.idle": "2025-01-03T00:57:16.440557Z",
     "shell.execute_reply": "2025-01-03T00:57:16.439225Z",
     "shell.execute_reply.started": "2025-01-03T00:57:16.434287Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Dimensões da base de dados\n",
    "print(\"Numero de linhas:\", base_original.shape[0]) #10.000 linhas originais.\n",
    "print(\"Numero de colunas:\", base_original.shape[1])# 18 Colunas (variaveis) originais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:57:16.443000Z",
     "iopub.status.busy": "2025-01-03T00:57:16.442605Z",
     "iopub.status.idle": "2025-01-03T00:57:16.468511Z",
     "shell.execute_reply": "2025-01-03T00:57:16.466913Z",
     "shell.execute_reply.started": "2025-01-03T00:57:16.442973Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Verificando nome das colunas e tipos\n",
    "base_original.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:57:16.470227Z",
     "iopub.status.busy": "2025-01-03T00:57:16.469878Z",
     "iopub.status.idle": "2025-01-03T00:57:16.497531Z",
     "shell.execute_reply": "2025-01-03T00:57:16.496280Z",
     "shell.execute_reply.started": "2025-01-03T00:57:16.470201Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#checando se há valores nulos \n",
    "base_original.isnull().sum()  \n",
    "\n",
    "#como podemos ver não há valores nulos em nenhuma das variáveis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:57:16.499123Z",
     "iopub.status.busy": "2025-01-03T00:57:16.498767Z",
     "iopub.status.idle": "2025-01-03T00:57:16.620050Z",
     "shell.execute_reply": "2025-01-03T00:57:16.619199Z",
     "shell.execute_reply.started": "2025-01-03T00:57:16.499089Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Resumo estatistico da base original\n",
    "base_original.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:57:16.621336Z",
     "iopub.status.busy": "2025-01-03T00:57:16.620609Z",
     "iopub.status.idle": "2025-01-03T00:57:16.707660Z",
     "shell.execute_reply": "2025-01-03T00:57:16.706392Z",
     "shell.execute_reply.started": "2025-01-03T00:57:16.621299Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Limpando variavéis que não tem interferencia na analise, \n",
    "#meramente identificadoras: \tRowNumber, CustomerId e Surname\n",
    "\n",
    "df = base_original[['CreditScore',\n",
    "                    'Gender',\n",
    "                    'Geography',\n",
    "                    'Age','Tenure',\n",
    "                    'Balance',\n",
    "                   'NumOfProducts',\n",
    "                    'HasCrCard',\n",
    "                    'IsActiveMember',\n",
    "                   'EstimatedSalary',\n",
    "                    'Complain',\n",
    "                    'Satisfaction Score',\n",
    "                   'Card Type',\n",
    "                    'Point Earned',\n",
    "                    'Exited'\n",
    "                   ]]\n",
    "\n",
    "\n",
    "# Resumo estatístico das variáveis quantitativas\n",
    "quanti = df[['EstimatedSalary', 'Balance', 'CreditScore', 'Age', 'Tenure', 'Point Earned']]\n",
    "resumo_estati_quant = quanti.describe().style.format(lambda x: f'{x:,.1f}'.replace(',', 'X').replace('.', ',').replace('X', '.')) # Formatação com 1 casa decimal e separadores invertidos\n",
    "\n",
    "resumo_estati_quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:57:16.709053Z",
     "iopub.status.busy": "2025-01-03T00:57:16.708488Z",
     "iopub.status.idle": "2025-01-03T00:57:16.731518Z",
     "shell.execute_reply": "2025-01-03T00:57:16.730254Z",
     "shell.execute_reply.started": "2025-01-03T00:57:16.709027Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#%% Resumo estatistico das varaiveis Quali (tabelas de frequencias)\n",
    "quali = df[['HasCrCard', 'IsActiveMember', 'Geography','Gender'\n",
    "            ,'Complain','Exited','Card Type']]\n",
    "quali = quali.astype('object')\n",
    "print(\"------------------------------------------\")\n",
    "print(quali['HasCrCard'].value_counts())\n",
    "print(\"------------------------------------------\")\n",
    "print(quali['IsActiveMember'].value_counts())\n",
    "print(\"------------------------------------------\")\n",
    "print(quali['Geography'].value_counts())\n",
    "print(\"------------------------------------------\")\n",
    "print(quali['Gender'].value_counts())\n",
    "print(\"------------------------------------------\")\n",
    "print(quali['Complain'].value_counts())\n",
    "print(\"------------------------------------------\")\n",
    "print(quali['Card Type'].value_counts())\n",
    "print(\"------------------------------------------\")\n",
    "print(quali['Exited'].value_counts())\n",
    "print(\"------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:57:16.732773Z",
     "iopub.status.busy": "2025-01-03T00:57:16.732470Z",
     "iopub.status.idle": "2025-01-03T00:57:16.763011Z",
     "shell.execute_reply": "2025-01-03T00:57:16.760562Z",
     "shell.execute_reply.started": "2025-01-03T00:57:16.732743Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Verificando tipos das variaveis quali (para morrer de certeza que estao no formato qualitativo, categorico)\n",
    "quali.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:57:16.765262Z",
     "iopub.status.busy": "2025-01-03T00:57:16.764825Z",
     "iopub.status.idle": "2025-01-03T00:57:17.420028Z",
     "shell.execute_reply": "2025-01-03T00:57:17.418585Z",
     "shell.execute_reply.started": "2025-01-03T00:57:16.765232Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Frequencia das variaveis categoricas \n",
    "#%%Analises gráficas: variaveis Categóricas \n",
    "\n",
    "\n",
    "def add_value_labels(ax):#funcao que adc rótulos de dados com fundo arredondado nas barras do gráfico\n",
    "    for p in ax.patches:\n",
    "        height = p.get_height()\n",
    "        color = p.get_facecolor()  # Obtém a cor da barra\n",
    "        # rótulo no centro da barra com fundo da mesma cor da barra e bordas arredondadas\n",
    "        ax.text(p.get_x() + p.get_width() / 2., height / 2.,\n",
    "                f'{int(height)}',  # Formata o valor para int\n",
    "                ha='center', va='center', fontsize=20, color='white', fontweight='bold',\n",
    "                bbox=dict(facecolor=color, edgecolor='none', alpha=0.7,\n",
    "                          boxstyle='round,pad=0.4', linewidth=1))\n",
    "\n",
    "plt.figure(figsize=(20, 25))\n",
    "\n",
    "\n",
    "#plt.suptitle('Frequência absoluta\\n das variaveis qualitativas', fontsize=45)\n",
    "\n",
    "# Geography\n",
    "plt.subplot(5, 2, 1)\n",
    "ax1 = plt.gca()\n",
    "ax1.set_title('Geography', fontsize=22, fontweight='bold')\n",
    "sns.countplot(x='Geography', palette='viridis', data=base_original, ax=ax1)\n",
    "plt.xlabel('') \n",
    "plt.ylabel('') \n",
    "plt.xticks(fontsize=15, rotation=0,fontweight='bold')\n",
    "plt.yticks([])\n",
    "add_value_labels(ax1)\n",
    "\n",
    "# Gender\n",
    "plt.subplot(5, 2, 2)\n",
    "ax2 = plt.gca()\n",
    "ax2.set_title('Gender', fontsize=22, fontweight='bold')\n",
    "sns.countplot(x='Gender', palette='viridis', data=base_original, ax=ax2)\n",
    "plt.xlabel('') \n",
    "plt.ylabel('') \n",
    "plt.xticks(fontsize=15, rotation=0,fontweight='bold')\n",
    "plt.yticks([])\n",
    "add_value_labels(ax2)\n",
    "# Complain\n",
    "plt.subplot(5, 2, 3)\n",
    "ax10 = plt.gca()\n",
    "ax10.set_title('Complain', fontsize=22, fontweight='bold')\n",
    "sns.countplot(x='Complain', palette='viridis', data=base_original, ax=ax10)\n",
    "plt.xlabel('') \n",
    "plt.ylabel('') \n",
    "plt.xticks(fontsize=15, rotation=0,fontweight='bold')\n",
    "plt.yticks([])\n",
    "add_value_labels(ax10)\n",
    "\n",
    "# HasCrCard\n",
    "plt.subplot(5, 2, 4)\n",
    "ax5 = plt.gca()\n",
    "ax5.set_title('HasCrCard', fontsize=22, fontweight='bold')\n",
    "sns.countplot(x='HasCrCard', palette='viridis', data=base_original, ax=ax5)\n",
    "plt.xlabel('') \n",
    "plt.ylabel('') \n",
    "plt.xticks(fontsize=15, rotation=0,fontweight='bold')\n",
    "plt.yticks([])\n",
    "add_value_labels(ax5)\n",
    "\n",
    "# IsActiveMember\n",
    "plt.subplot(5, 2, 5)\n",
    "ax6 = plt.gca()\n",
    "ax6.set_title('IsActiveMember', fontsize=22, fontweight='bold')\n",
    "sns.countplot(x='IsActiveMember', palette='viridis', data=base_original, ax=ax6)\n",
    "plt.xlabel('') \n",
    "plt.ylabel('') \n",
    "plt.xticks(fontsize=15, rotation=0,fontweight='bold')\n",
    "plt.yticks([])\n",
    "add_value_labels(ax6)\n",
    "\n",
    "# Card Type\n",
    "plt.subplot(5, 2, 6)\n",
    "ax10 = plt.gca()\n",
    "ax10.set_title('Card Type', fontsize=22, fontweight='bold')\n",
    "sns.countplot(x='Card Type', palette='viridis', data=base_original, ax=ax10)\n",
    "plt.xlabel('') \n",
    "plt.ylabel('') \n",
    "plt.xticks(fontsize=15, rotation=0,fontweight='bold')\n",
    "plt.yticks([])\n",
    "add_value_labels(ax10)\n",
    "\n",
    "# Exited\n",
    "plt.subplot(5, 2, 7)\n",
    "ax7 = plt.gca()\n",
    "ax7.set_title('Exited: churn variable', fontsize=22, fontweight='bold')\n",
    "custom_palette = ['green', 'red']\n",
    "sns.countplot(x='Exited', palette=custom_palette, data=base_original, ax=ax7)\n",
    "plt.xlabel('') \n",
    "plt.ylabel('') \n",
    "plt.xticks(fontsize=15, rotation=0,fontweight='bold')\n",
    "plt.yticks([])\n",
    "add_value_labels(ax7)\n",
    "\n",
    "\n",
    "ax7.set_xticks([0, 1])  # Define os ticks manualmente\n",
    "ax7.set_xticklabels(['Não', 'Sim'], fontsize=15, fontweight='bold')  # Rótulos personalizados\n",
    "add_value_labels(ax7)\n",
    "\n",
    "\n",
    "# ajusta a distância entre os gráficos\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:57:17.421339Z",
     "iopub.status.busy": "2025-01-03T00:57:17.421043Z",
     "iopub.status.idle": "2025-01-03T00:57:19.006746Z",
     "shell.execute_reply": "2025-01-03T00:57:19.005458Z",
     "shell.execute_reply.started": "2025-01-03T00:57:17.421317Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#%% Variável TARGET em relação as demais variáveis \n",
    "\n",
    "plt.figure(figsize=(20, 25))\n",
    "\n",
    "def add_legend(ax):\n",
    "    \"\"\"Adiciona a legenda no canto superior direito e garante que os rótulos sejam exibidos\"\"\"\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    if not handles:\n",
    "        # Se não houver handles, adicione manualmente\n",
    "        handles = [plt.Rectangle((0,0),1,1, color=c) for c in ['green', 'red']]\n",
    "        labels = ['Not Exited', 'Exited']\n",
    "    # Adiciona a legenda fora da área das barras\n",
    "    ax.legend(handles, labels, loc='upper left', fontsize=14, title='Exited', title_fontsize='13',\n",
    "              bbox_to_anchor=(1.0, 1))  # Ajusta a posição da legenda para fora das barras\n",
    "\n",
    "# Geography\n",
    "plt.subplot(5, 2, 1)\n",
    "counts = base_original.groupby(['Geography', 'Exited']).size().unstack().fillna(0)\n",
    "ax = counts.plot(kind='bar', stacked=True, color=['green', 'red'], ax=plt.gca())  \n",
    "plt.title('Exited by Geography', fontsize=22, fontweight='bold')\n",
    "plt.xlabel('Geography', fontsize=16)\n",
    "plt.ylabel('', fontsize=16)\n",
    "plt.xticks(fontsize=14, rotation=0,fontweight='bold')\n",
    "plt.yticks(fontsize=14)\n",
    "add_legend(ax)\n",
    "\n",
    "# Gender\n",
    "plt.subplot(5, 2, 2)\n",
    "counts = base_original.groupby(['Gender', 'Exited']).size().unstack().fillna(0)\n",
    "ax = counts.plot(kind='bar', stacked=True, color=['green', 'red'], ax=plt.gca()) \n",
    "plt.title('Exited by Gender', fontsize=22, fontweight='bold')\n",
    "plt.xlabel('Gender', fontsize=16)\n",
    "plt.ylabel('', fontsize=16)\n",
    "plt.xticks(fontsize=14, rotation=0,fontweight='bold')\n",
    "plt.yticks(fontsize=14)\n",
    "add_legend(ax)\n",
    "\n",
    "# NumOfProducts\n",
    "plt.subplot(5, 2, 3)\n",
    "counts = base_original.groupby(['NumOfProducts', 'Exited']).size().unstack().fillna(0)\n",
    "ax = counts.plot(kind='bar', stacked=True, color=['green', 'red'], ax=plt.gca())  \n",
    "plt.title('Exited by NumOfProducts', fontsize=22, fontweight='bold')\n",
    "plt.xlabel('NumOfProducts', fontsize=16)\n",
    "plt.ylabel('', fontsize=16)\n",
    "plt.xticks(fontsize=14, rotation=0,fontweight='bold')\n",
    "plt.yticks(fontsize=14)\n",
    "add_legend(ax)\n",
    "\n",
    "# HasCrCard\n",
    "plt.subplot(5, 2, 4)\n",
    "counts = base_original.groupby(['HasCrCard', 'Exited']).size().unstack().fillna(0)\n",
    "ax = counts.plot(kind='bar', stacked=True, color=['green', 'red'], ax=plt.gca())  \n",
    "plt.title('Exited by HasCrCard', fontsize=22, fontweight='bold')\n",
    "plt.xlabel('HasCrCard', fontsize=16)\n",
    "plt.ylabel('', fontsize=16)\n",
    "plt.xticks(fontsize=14, rotation=0,fontweight='bold')\n",
    "plt.yticks(fontsize=14)\n",
    "add_legend(ax)\n",
    "\n",
    "# IsActiveMember\n",
    "plt.subplot(5, 2, 5)\n",
    "counts = base_original.groupby(['IsActiveMember', 'Exited']).size().unstack().fillna(0)\n",
    "ax = counts.plot(kind='bar', stacked=True, color=['green', 'red'], ax=plt.gca()) \n",
    "plt.title('Exited by IsActiveMember', fontsize=22, fontweight='bold')\n",
    "plt.xlabel('IsActiveMember', fontsize=16)\n",
    "plt.ylabel('', fontsize=16)\n",
    "plt.xticks(fontsize=14, rotation=0,fontweight='bold')\n",
    "plt.yticks(fontsize=14)\n",
    "add_legend(ax)\n",
    "\n",
    "# Complain\n",
    "plt.subplot(5, 2, 6)\n",
    "counts = base_original.groupby(['Complain', 'Exited']).size().unstack().fillna(0)\n",
    "ax = counts.plot(kind='bar', stacked=True, color=['green', 'red'], ax=plt.gca())  \n",
    "plt.title('Exited by Complain', fontsize=22, fontweight='bold')\n",
    "plt.xlabel('Complain', fontsize=16)\n",
    "plt.ylabel('', fontsize=16)\n",
    "plt.xticks(fontsize=14, rotation=0,fontweight='bold')\n",
    "plt.yticks(fontsize=14)\n",
    "add_legend(ax)\n",
    "\n",
    "# Satisfaction Score\n",
    "plt.subplot(5, 2, 7)\n",
    "counts = base_original.groupby(['Satisfaction Score', 'Exited']).size().unstack().fillna(0)\n",
    "ax = counts.plot(kind='bar', stacked=True, color=['green', 'red'], ax=plt.gca())  \n",
    "plt.title('Exited by Satisfaction Score', fontsize=22, fontweight='bold')\n",
    "plt.xlabel('Satisfaction Score', fontsize=16)\n",
    "plt.ylabel('', fontsize=16)\n",
    "plt.xticks(fontsize=14, rotation=0,fontweight='bold')\n",
    "plt.yticks(fontsize=14)\n",
    "add_legend(ax)\n",
    "\n",
    "# Card Type\n",
    "plt.subplot(5, 2, 8)\n",
    "counts = base_original.groupby(['Card Type', 'Exited']).size().unstack().fillna(0)\n",
    "ax = counts.plot(kind='bar', stacked=True, color=['green', 'red'], ax=plt.gca())  \n",
    "plt.title('Exited by Card Type', fontsize=22, fontweight='bold')\n",
    "plt.xlabel('Card Type', fontsize=16)\n",
    "plt.ylabel('', fontsize=16)\n",
    "plt.xticks(fontsize=14, rotation=0,fontweight='bold')\n",
    "plt.yticks(fontsize=14)\n",
    "add_legend(ax)\n",
    "\n",
    "# Ajustar a distância entre os gráficos\n",
    "plt.subplots_adjust(hspace=0.7, wspace=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variaveis Dummies e Correlações "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:57:19.011064Z",
     "iopub.status.busy": "2025-01-03T00:57:19.010664Z",
     "iopub.status.idle": "2025-01-03T00:57:19.038178Z",
     "shell.execute_reply": "2025-01-03T00:57:19.036809Z",
     "shell.execute_reply.started": "2025-01-03T00:57:19.011040Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Dumizando\n",
    "\n",
    "# Transformando colunas específicas em tipo object usando .loc para evitar o Warning\n",
    "cols_to_transform = ['HasCrCard', 'IsActiveMember', 'Geography', 'Gender', 'Card Type']\n",
    "df.loc[:, cols_to_transform] = df[cols_to_transform].astype('object')\n",
    "\n",
    "\n",
    "\n",
    "# Gerando as dummies\n",
    "df_dummies = pd.get_dummies(df,\n",
    "                           columns=['HasCrCard',\n",
    "                                    'IsActiveMember', \n",
    "                                    'Geography',\n",
    "                                    'Gender',\n",
    "                                    'Card Type'],\n",
    "                           dtype=int,\n",
    "                           drop_first=False)\n",
    "\n",
    "\n",
    "#Transformando Target em numérica\n",
    "df_dummies['Exited'] = df_dummies['Exited'].astype('int64')\n",
    "\n",
    "\n",
    "\n",
    "#verificando tipos gerados\n",
    "df_dummies.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:57:19.039766Z",
     "iopub.status.busy": "2025-01-03T00:57:19.039474Z",
     "iopub.status.idle": "2025-01-03T00:57:20.406993Z",
     "shell.execute_reply": "2025-01-03T00:57:20.404907Z",
     "shell.execute_reply.started": "2025-01-03T00:57:19.039739Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#%%Analises gráficas: correlação das variaveis Numéricas \n",
    "\n",
    "correlation_matrix = df_dummies.corr().round(2)\n",
    "correlation_matrix\n",
    "\n",
    "# Mapa de calor das variaveis quanti\n",
    "plt.figure(figsize=(30, 20))\n",
    "heatmap = sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\",\n",
    "                      cmap=plt.cm.Blues,\n",
    "                      annot_kws={'size': 15}, vmin=-1, vmax=1)\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(), fontsize=17)\n",
    "heatmap.set_yticklabels(heatmap.get_yticklabels(), fontsize=17)\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=17)\n",
    "plt.title('Correlação das Variáveis Quantitativas', fontsize=25)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "#apresentaram correlacao alta, para evitar multicolinearidade foram removidas \n",
    "df_dummies = df_dummies.drop(columns=['HasCrCard_0','IsActiveMember_0','Gender_Female','Complain'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separação Treino e Teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:57:20.408573Z",
     "iopub.status.busy": "2025-01-03T00:57:20.408270Z",
     "iopub.status.idle": "2025-01-03T00:57:20.715495Z",
     "shell.execute_reply": "2025-01-03T00:57:20.714223Z",
     "shell.execute_reply.started": "2025-01-03T00:57:20.408550Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#X ---> Variáveis explicativas \n",
    "\n",
    "#Y ---> Evento de estudo (variável TARGET)\n",
    "\n",
    "X = df_dummies .drop('Exited', axis=1)\n",
    "\n",
    "y =  df_dummies['Exited']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Verificando a proporção de eventos de churn (TARGET) nas bases de TREINO e TESTE \n",
    "\n",
    "# Contando os valores \n",
    "churn_counts_train = y_train.value_counts()\n",
    "churn_counts_test = y_test.value_counts()\n",
    "\n",
    "# Criando o plot com subplots lado a lado\n",
    "fig, axs = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "# Adicionando título geral ao plot\n",
    "fig.suptitle('Proporção da Variável Churn entre Treino e Teste', fontsize=35)\n",
    "\n",
    "#definindo a paleta de cor padrao a ser usada nos dois graficos \n",
    "cmap = plt.get_cmap('viridis', 2)\n",
    "\n",
    "# Gráfico da base de treino\n",
    "bars_train = axs[0].bar(churn_counts_train.index, churn_counts_train.values, color=cmap(range(2)))\n",
    "axs[0].set_title('Base de Treino', fontsize=25)\n",
    "axs[0].set_xlabel('Churn', fontsize=20)\n",
    "axs[0].set_ylabel('Contagem', fontsize=20)\n",
    "axs[0].set_xticks([0, 1])\n",
    "axs[0].set_xticklabels(['0', '1'], fontsize=20)\n",
    "\n",
    "# Ocultando os valores do eixo y\n",
    "axs[0].set_yticklabels([])\n",
    "\n",
    "# Adicionando rótulos de dados nas barras da base de treino com valor absoluto e percentual\n",
    "total_train = churn_counts_train.sum()\n",
    "for bar in bars_train:\n",
    "    count = int(bar.get_height())\n",
    "    percentage = round(count / total_train * 100)  # Arredonda a porcentagem\n",
    "    label = f'{count} ({percentage}%)'  # Exibe o valor absoluto e o percentual\n",
    "    axs[0].text(bar.get_x() + bar.get_width() / 2, bar.get_height() / 2, \n",
    "                label, ha='center', color='gray', fontsize=25, weight='bold')\n",
    "\n",
    "# Gráfico da base de teste\n",
    "bars_test = axs[1].bar(churn_counts_test.index, churn_counts_test.values, color=cmap(range(2)))\n",
    "axs[1].set_title('Base de Teste', fontsize=25)\n",
    "axs[1].set_xlabel('Churn', fontsize=20)\n",
    "axs[1].set_ylabel('Contagem', fontsize=20)\n",
    "axs[1].set_xticks([0, 1])\n",
    "axs[1].set_xticklabels(['0', '1'], fontsize=20)\n",
    "\n",
    "# Ocultando os valores do eixo y\n",
    "axs[1].set_yticklabels([])\n",
    "\n",
    "# Adicionando rótulos de dados nas barras da base de teste com valor absoluto e percentual\n",
    "total_test = churn_counts_test.sum()\n",
    "for bar in bars_test:\n",
    "    count = int(bar.get_height())\n",
    "    percentage = round(count / total_test * 100)  # Arredonda a porcentagem\n",
    "    label = f'{count} ({percentage}%)'  # Exibe o valor absoluto e o percentual\n",
    "    axs[1].text(bar.get_x() + bar.get_width() / 2, bar.get_height() / 2, \n",
    "                label, ha='center', color='gray', fontsize=25, weight='bold')\n",
    "\n",
    "# Ajustar o layout para evitar sobreposição\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])  # Deixa espaço para o título principal\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:57:20.716539Z",
     "iopub.status.busy": "2025-01-03T00:57:20.716278Z",
     "iopub.status.idle": "2025-01-03T00:57:21.867305Z",
     "shell.execute_reply": "2025-01-03T00:57:21.865808Z",
     "shell.execute_reply.started": "2025-01-03T00:57:20.716517Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#%% Testando Multicolinearidade na base de treino\n",
    "\n",
    "#Aqui é só para morrer de certeza, para evitar que o modelo treine errado ou sofra com multicolinearidade. \n",
    "\n",
    "# todo esse processo de tirar as variaveis que tem alta correlacao com a variavel target pode ser analisado se realmente é necessario, a depender do modelo \n",
    "# existem modelos que capturam bem isso e não são afetados pela multicolinearidade, nesse estudo vamos testar das duas formas, com e sem essas variáveis. \n",
    "\n",
    "teste_multco_treino = pd.concat([X_train,y_train], axis = 1)\n",
    "\n",
    "correlation_matrix_treino = teste_multco_treino.corr().round(2)\n",
    "correlation_matrix_treino\n",
    "\n",
    "# Mapa de calor das variaveis quanti (SEM COMPLAIN)\n",
    "plt.figure(figsize=(30, 20))\n",
    "heatmap = sns.heatmap(correlation_matrix_treino, annot=True, fmt=\".2f\",\n",
    "                      cmap=plt.cm.viridis_r, # é importante notar que a paleta de cores viridis (ou viridis_r para o inverso de cores) é uma paleta especial \n",
    "                                             # para facilitar a visualizacao por pessoas com dificuldades, como os daltonicos. \n",
    "                      annot_kws={'size': 15}, vmin=-1, vmax=1)\n",
    "heatmap.set_xticklabels(heatmap.get_xticklabels(), fontsize=17)\n",
    "heatmap.set_yticklabels(heatmap.get_yticklabels(), fontsize=17)\n",
    "plt.title('Correlação das Variáveis Quantitativas na Base de Treino',fontsize=25)\n",
    "cbar = heatmap.collections[0].colorbar\n",
    "cbar.ax.tick_params(labelsize=17)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analise e tratamento de Outliers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:57:21.868666Z",
     "iopub.status.busy": "2025-01-03T00:57:21.868394Z",
     "iopub.status.idle": "2025-01-03T00:57:23.794322Z",
     "shell.execute_reply": "2025-01-03T00:57:23.792917Z",
     "shell.execute_reply.started": "2025-01-03T00:57:21.868644Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#%% analise de outliers das variaveis na base de treino \n",
    "\n",
    "\n",
    "#avariaveis analisadas (numéricas)\n",
    "variaveis = [\n",
    "    'CreditScore',\n",
    "    'Age',\n",
    "    'Tenure',\n",
    "    'Balance',\n",
    "    'NumOfProducts',\n",
    "    'EstimatedSalary',\n",
    "    'Satisfaction Score',\n",
    "    'Point Earned'\n",
    "]\n",
    "\n",
    "# subplots\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# boxplots separados para cada variável\n",
    "for i, var in enumerate(variaveis):\n",
    "    plt.subplot(3, 3, i + 1)  # 3 linhas e 3 colunas\n",
    "    sns.boxplot(y=teste_multco_treino[var],\n",
    "               boxprops=dict(facecolor='lightblue'))  # Cor interna do boxplot)  \n",
    "    plt.title(f'Boxplot {var}', fontsize=12)\n",
    "\n",
    "\n",
    "#  título geral\n",
    "plt.suptitle('Análise de Outliers nas Variáveis(treino) - antes de \"winsorization\" ', fontsize=20)\n",
    "\n",
    "# Ajuste de layout\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])  # Ajuste de layout sem sobrepor o título\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#aplicando procedimento de truncamento ou winsorization nos outliers\n",
    "\n",
    "# ---> substitui os outliers pelos valores dos limites inferior e superior, \n",
    "#de acordo com a posicao de cada outliers na distribuição dos dados\n",
    "\n",
    "# Função para tratar outliers\n",
    "def tratar_outliers(df, coluna):\n",
    "    Q1 = df[coluna].quantile(0.25)\n",
    "    Q3 = df[coluna].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    limite_inferior = Q1 - 1.5 * IQR\n",
    "    limite_superior = Q3 + 1.5 * IQR\n",
    "    \n",
    "    # Substitui outliers pelo limite inferior ou superior\n",
    "    df[coluna] = np.where(df[coluna] < limite_inferior, limite_inferior, df[coluna])\n",
    "    df[coluna] = np.where(df[coluna] > limite_superior, limite_superior, df[coluna])\n",
    "\n",
    "# Aplicando a função nas variáveis \n",
    "variaveis_para_tratar = ['Age', 'CreditScore', 'NumOfProducts']\n",
    "\n",
    "for variavel in variaveis_para_tratar:\n",
    "    tratar_outliers(teste_multco_treino, variavel)\n",
    "    \n",
    "# subplot\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# boxplots separados para cada variável\n",
    "for i, var in enumerate(variaveis):\n",
    "    plt.subplot(3, 3, i + 1)  # 3 linhas e 3 colunas\n",
    "    sns.boxplot(y=teste_multco_treino[var],\n",
    "               boxprops=dict(facecolor='green'))  # Cor interna do boxplot)  # Usar o nome da variável diretamente\n",
    "            \n",
    "    plt.title(f'Boxplot {var}', fontsize=12)\n",
    "\n",
    "# título geral\n",
    "plt.suptitle('Análise de Outliers nas Variáveis(treino) - depois de \"winsorization\" ', fontsize=20)\n",
    "\n",
    "# Ajustando layout\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])  # Ajusta o layout sem sobrepor o título\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:57:23.795625Z",
     "iopub.status.busy": "2025-01-03T00:57:23.795299Z",
     "iopub.status.idle": "2025-01-03T00:57:23.819105Z",
     "shell.execute_reply": "2025-01-03T00:57:23.817699Z",
     "shell.execute_reply.started": "2025-01-03T00:57:23.795596Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#%% Separando novamente as bases de treino e teste depois de tratar os outliers APENAS na base de TREINO  \n",
    "\n",
    "# Divisão dos dados\n",
    "X = teste_multco_treino.drop('Exited', axis=1)\n",
    "y = teste_multco_treino['Exited']\n",
    "\n",
    "# Divisão dos dados entre treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y  # Stratify para lidar com desbalanceamento\n",
    ")\n",
    "\n",
    "# Divisão dos dados\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y  # Adicionado stratify para lidar com desbalanceamento\n",
    ")\n",
    "\n",
    "\n",
    "print('---------------------------------------')\n",
    "print(X_train.isnull().sum())\n",
    "print('---------------------------------------')\n",
    "print('---------------------------------------')\n",
    "print(X_train.dtypes)\n",
    "print('---------------------------------------')\n",
    "print('---------------------------------------')\n",
    "print(y_train.value_counts())\n",
    "print('---------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelagem: aplicando MLP \n",
    "\n",
    "Ver se vale a pena testar modelo com as variaveis quev foram removidas por multicolinearidade. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-03T00:57:23.820546Z",
     "iopub.status.busy": "2025-01-03T00:57:23.820254Z",
     "iopub.status.idle": "2025-01-03T04:02:36.741261Z",
     "shell.execute_reply": "2025-01-03T04:02:36.739373Z",
     "shell.execute_reply.started": "2025-01-03T00:57:23.820525Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#%% Rede Neural Perceptron Multicamadas com GridSearchCV e validação cruzada (com processamento padrão)\n",
    "\n",
    "# início\n",
    "start_time_utc = datetime.utcnow() - timedelta(hours=3)\n",
    "print('------------------------')\n",
    "print(\"Início:\", start_time_utc)\n",
    "print('------------------------')\n",
    "print('------------------------')\n",
    "print(\"MLP - Multi-Layer Perceptron (Aprimorado)\")\n",
    "print('------------------------')\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, \n",
    "    classification_report, confusion_matrix, roc_curve\n",
    ")\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, \n",
    "    classification_report, confusion_matrix, roc_curve\n",
    ")\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Redefinindo o grid de parâmetros\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(50,), (100,), (150,), (200,),(500,)],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'alpha': [1e-4,1e-2],  # Aumentando a regularização\n",
    "    'learning_rate_init': [1e-4, 1e-5, 1e-6],\n",
    "    'learning_rate_init': [0.001, 0.01],\n",
    "    'max_iter': [3000,4000],\n",
    "    'batch_size': [16, 32],\n",
    "    'early_stopping': [True],\n",
    "    'validation_fraction': [0.1,0.2]\n",
    "}\n",
    "\n",
    "# Aplicando SMOTE para balancear as classes no conjunto de treinamento\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "# Convertendo os dados de treino para DataFrame, caso deseje acessar com os índices corretamente\n",
    "import pandas as pd\n",
    "X_train_resampled = pd.DataFrame(X_train_resampled, columns=X_train.columns)\n",
    "y_train_resampled = pd.Series(y_train_resampled)\n",
    "\n",
    "# Criando o modelo MLP\n",
    "mlp = MLPClassifier(random_state=42)\n",
    "\n",
    "# Usando validação cruzada estratificada\n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "\n",
    "# Configurando o RandomizedSearchCV\n",
    "random_search  = RandomizedSearchCV(\n",
    "    estimator=mlp,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=100,  # Número de combinações aleatórias\n",
    "    cv=cv,\n",
    "    n_jobs=-1,\n",
    "    verbose=2,\n",
    "    scoring='roc_auc',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Inicializando a barra de progresso para cada fold\n",
    "fold_bar = tqdm(total=10, desc=\"Fold Progress\", ncols=100, position=0)\n",
    "\n",
    "# Função que substitui o comportamento de GridSearchCV para atualizações de progresso\n",
    "def fit_with_progress(X_train_resampled, y_train_resampled):\n",
    "    # Dividindo o treino em 3 folds\n",
    "    for fold_idx, (train_idx, val_idx) in enumerate(cv.split(X_train_resampled, y_train_resampled)):\n",
    "        fold_bar.set_description(f\"Fold {fold_idx + 1} de 10\")\n",
    "        fold_bar.update(1)  # Atualiza a barra de progresso do fold\n",
    "\n",
    "        X_train_fold, X_val_fold = X_train_resampled.iloc[train_idx], X_train_resampled.iloc[val_idx]\n",
    "        y_train_fold, y_val_fold = y_train_resampled.iloc[train_idx], y_train_resampled.iloc[val_idx]\n",
    "\n",
    "        # Ajustando o GridSearchCV\n",
    "        random_search.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Iterando sobre os melhores parâmetros após o ajuste\n",
    "        for params in random_search.cv_results_['params']:\n",
    "            mlp.set_params(**params)  # Ajustando os parâmetros do modelo\n",
    "            mlp.fit(X_train_fold, y_train_fold)\n",
    "\n",
    "# Treinando o modelo com a validação cruzada e o GridSearchCV\n",
    "fit_with_progress(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Recuperando o melhor modelo\n",
    "best_model = random_search .best_estimator_\n",
    "\n",
    "# Exibindo os melhores parâmetros encontrados\n",
    "print(f\"Melhores parâmetros: {random_search.best_params_}\")\n",
    "\n",
    "# Previsões e probabilidades para treino e teste\n",
    "y_train_pred = best_model.predict(X_train_resampled)\n",
    "y_train_prob = best_model.predict_proba(X_train_resampled)[:, 1]\n",
    "\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "y_test_prob = best_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Cálculo das métricas de teste\n",
    "accuracy = accuracy_score(y_test, y_test_pred)\n",
    "precision = precision_score(y_test, y_test_pred)\n",
    "recall = recall_score(y_test, y_test_pred)\n",
    "f1 = f1_score(y_test, y_test_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_test_prob)\n",
    "\n",
    "# Gerando a matriz de confusão\n",
    "plt.figure(figsize=(8, 6))\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Não Exited', 'Exited'], yticklabels=['Não Exited', 'Exited'])\n",
    "plt.xlabel('Predição')\n",
    "plt.ylabel('Real')\n",
    "plt.title('Matriz de Confusão')\n",
    "plt.show()\n",
    "\n",
    "# Curva ROC\n",
    "# Gráficos da Curva ROC para Treino e Teste\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "# ROC - Treino\n",
    "fpr_train, tpr_train, _ = roc_curve(y_train_resampled, y_train_prob)\n",
    "roc_auc_train = roc_auc_score(y_train_resampled, y_train_prob)\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title(f\"Curva ROC - Treino (AUC = {roc_auc_train:.2f})\")\n",
    "plt.plot(fpr_train, tpr_train, color='blue', label=f'AUC = {roc_auc_train:.2f}')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('Taxa de Falsos Positivos')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# ROC - Teste\n",
    "fpr_test, tpr_test, _ = roc_curve(y_test, y_test_prob)\n",
    "roc_auc_test = roc_auc_score(y_test, y_test_prob)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.title(f\"Curva ROC - Teste (AUC = {roc_auc_test:.2f})\")\n",
    "plt.plot(fpr_test, tpr_test, color='green', label=f'AUC = {roc_auc_test:.2f}')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('Taxa de Falsos Positivos')\n",
    "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Relatório de desempenho\n",
    "print(\"\\nRelatório de classificação - Treino:\\n\", classification_report(y_train_resampled, y_train_pred))\n",
    "print(\"\\nRelatório de classificação - Teste:\\n\", classification_report(y_test, y_test_pred))\n",
    "\n",
    "# Curva de Perda\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(best_model.loss_curve_, label='Perda durante o treinamento')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Perda')\n",
    "plt.title('Curva de Perda do Modelo')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Relatório de desempenho\n",
    "print('Relatório de classificação:', classification_report(y_test, y_test_pred))\n",
    "print(\"AUC-ROC:\", roc_auc)\n",
    "print(\"F1-Score:\", f1)\n",
    "\n",
    "# Exibir as métricas\n",
    "print('------------------------')\n",
    "print('Métricas do Conjunto de Teste para o Modelo Neural:')\n",
    "print(f\"ROC AUC: {roc_auc:.4f}\")\n",
    "print(f\"Acurácia: {accuracy:.4f}\")\n",
    "print(f\"Precisão: {precision:.4f}\")\n",
    "print(f\"Revocação: {recall:.4f}\")\n",
    "print(f\"F1-Score: {f1:.4f}\")\n",
    "print('------------------------')\n",
    "\n",
    "# Tempo total de execução\n",
    "# fim\n",
    "t_end = datetime.utcnow() - timedelta(hours=3)\n",
    "print('------------------------')\n",
    "print(\"Fim:\", t_end)\n",
    "print('------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 3197960,
     "sourceId": 5550559,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30822,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
