{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5550559,"sourceType":"datasetVersion","datasetId":3197960}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Bibliotecas \n","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #graficos\nimport matplotlib.cm as cm\nimport seaborn as sns #graficos\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import (classification_report, confusion_matrix, roc_auc_score,  precision_score, recall_score, \n                             f1_score, accuracy_score, roc_curve, auc, make_scorer)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom datetime import datetime, timedelta\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Dicinário de Dados \n\n\n| **Variável**         | **Tipo**   | **Descrição**                                                                                                                                     |\n|-----------------------|------------|---------------------------------------------------------------------------------------------------------------------------------------------------|\n| RowNumber            | int64      | Número do registro (linhas), sem efeito na construção de modelos.                                                                                |\n| CustomerId           | int64      | ID do cliente, sem efeito sobre o estudo.                                                                                                       |\n| Surname              | object     | Sobrenome do cliente, sem impacto na análise.                                                                                                   |\n| CreditScore          | int64      | Pontuação de crédito, pode indicar tendência de permanência de clientes com pontuação alta.                                                     |\n| Geography            | object     | Localização do cliente, pode influenciar a decisão de evasão.                                                                                   |\n| Gender               | object     | Gênero do cliente, possível influência na evasão.                                                                                               |\n| Age                  | int64      | Idade do cliente, clientes mais velhos tendem a permanecer.                                                                                     |\n| Tenure               | int64      | Anos que o cliente está no banco, clientes novos têm maior chance de evasão.                                                                    |\n| Balance              | float64    | Saldo na conta, pessoas com saldos altos são menos propensas a sair.                                                                            |\n| NumOfProducts        | int64      | Número de produtos adquiridos pelo cliente.                                                                                                    |\n| HasCrCard            | int64      | Indica se o cliente tem cartão de crédito, clientes com cartão são menos propensos à evasão.                                                    |\n| IsActiveMember       | int64      | Clientes ativos têm menor chance de evasão.                                                                                                    |\n| EstimatedSalary      | float64    | Salário estimado, clientes com salários mais altos tendem a permanecer.                                                                         |\n| Exited               | int64      | Indica se o cliente saiu ou não do banco, variável de predição (“churn”).                                                                       |\n| Complain             | int64      | Indica se o cliente fez reclamação.                                                                                                             |\n| Satisfaction Score   | int64      | Pontuação de satisfação com a resolução de reclamação.                                                                                          |\n| Card Type            | object     | Tipo de cartão que o cliente possui.                                                                                                            |\n| Points Earned        | int64      | Pontos ganhos pelo cliente.                                                                                                                     |\n","metadata":{}},{"cell_type":"markdown","source":"#  Análise Exploratória (EDA) & Data Prep\n","metadata":{"execution":{"iopub.status.busy":"2024-12-21T05:51:49.217244Z","iopub.execute_input":"2024-12-21T05:51:49.217695Z","iopub.status.idle":"2024-12-21T05:51:49.222777Z","shell.execute_reply.started":"2024-12-21T05:51:49.217658Z","shell.execute_reply":"2024-12-21T05:51:49.221466Z"}}},{"cell_type":"code","source":"# base de dados\nbase_original = pd.read_csv('/kaggle/input/Customer-Churn-Records.csv', sep=',')\n\n#configs para nao quebrar linhas no print do  df\npd.set_option('display.expand_frame_repr', False) \npd.set_option('display.max_columns', None)\n\n#primeiras linhas \nbase_original.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Dimensões da base de dados\nprint(\"Numero de linhas:\", base_original.shape[0]) #10.000 linhas originais.\nprint(\"Numero de colunas:\", base_original.shape[1])# 18 Colunas (variaveis) originais.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Verificando nome das colunas e tipos\nbase_original.dtypes","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#checando se há valores nulos \nbase_original.isnull().sum()  \n\n#como podemos ver não há valores nulos em nenhuma das variáveis","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Resumo estatistico da base original\nbase_original.describe()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Limpando variavéis que não tem interferencia na analise, \n#meramente identificadoras: \tRowNumber, CustomerId e Surname\n\ndf = base_original[['CreditScore',\n                    'Gender',\n                    'Geography',\n                    'Age','Tenure',\n                    'Balance',\n                   'NumOfProducts',\n                    'HasCrCard',\n                    'IsActiveMember',\n                   'EstimatedSalary',\n                    'Complain',\n                    'Satisfaction Score',\n                   'Card Type',\n                    'Point Earned',\n                    'Exited'\n                   ]]\n\n\n# Resumo estatístico das variáveis quantitativas\nquanti = df[['EstimatedSalary', 'Balance', 'CreditScore', 'Age', 'Tenure', 'Point Earned']]\nresumo_estati_quant = quanti.describe().style.format(lambda x: f'{x:,.1f}'.replace(',', 'X').replace('.', ',').replace('X', '.')) # Formatação com 1 casa decimal e separadores invertidos\n\nresumo_estati_quant","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#%% Resumo estatistico das varaiveis Quali (tabelas de frequencias)\nquali = df[['HasCrCard', 'IsActiveMember', 'Geography','Gender'\n            ,'Complain','Exited','Card Type']]\nquali = quali.astype('object')\nprint(\"------------------------------------------\")\nprint(quali['HasCrCard'].value_counts())\nprint(\"------------------------------------------\")\nprint(quali['IsActiveMember'].value_counts())\nprint(\"------------------------------------------\")\nprint(quali['Geography'].value_counts())\nprint(\"------------------------------------------\")\nprint(quali['Gender'].value_counts())\nprint(\"------------------------------------------\")\nprint(quali['Complain'].value_counts())\nprint(\"------------------------------------------\")\nprint(quali['Card Type'].value_counts())\nprint(\"------------------------------------------\")\nprint(quali['Exited'].value_counts())\nprint(\"------------------------------------------\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Verificando tipos das variaveis quali (para morrer de certeza que estao no formato qualitativo, categorico)\nquali.dtypes","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Frequencia das variaveis categoricas \n#%%Analises gráficas: variaveis Categóricas \n\n\ndef add_value_labels(ax):#funcao que adc rótulos de dados com fundo arredondado nas barras do gráfico\n    for p in ax.patches:\n        height = p.get_height()\n        color = p.get_facecolor()  # Obtém a cor da barra\n        # rótulo no centro da barra com fundo da mesma cor da barra e bordas arredondadas\n        ax.text(p.get_x() + p.get_width() / 2., height / 2.,\n                f'{int(height)}',  # Formata o valor para int\n                ha='center', va='center', fontsize=20, color='white', fontweight='bold',\n                bbox=dict(facecolor=color, edgecolor='none', alpha=0.7,\n                          boxstyle='round,pad=0.4', linewidth=1))\n\nplt.figure(figsize=(20, 25))\n\n\n#plt.suptitle('Frequência absoluta\\n das variaveis qualitativas', fontsize=45)\n\n# Geography\nplt.subplot(5, 2, 1)\nax1 = plt.gca()\nax1.set_title('Geography', fontsize=22, fontweight='bold')\nsns.countplot(x='Geography', palette='viridis', data=base_original, ax=ax1)\nplt.xlabel('') \nplt.ylabel('') \nplt.xticks(fontsize=15, rotation=0,fontweight='bold')\nplt.yticks([])\nadd_value_labels(ax1)\n\n# Gender\nplt.subplot(5, 2, 2)\nax2 = plt.gca()\nax2.set_title('Gender', fontsize=22, fontweight='bold')\nsns.countplot(x='Gender', palette='viridis', data=base_original, ax=ax2)\nplt.xlabel('') \nplt.ylabel('') \nplt.xticks(fontsize=15, rotation=0,fontweight='bold')\nplt.yticks([])\nadd_value_labels(ax2)\n# Complain\nplt.subplot(5, 2, 3)\nax10 = plt.gca()\nax10.set_title('Complain', fontsize=22, fontweight='bold')\nsns.countplot(x='Complain', palette='viridis', data=base_original, ax=ax10)\nplt.xlabel('') \nplt.ylabel('') \nplt.xticks(fontsize=15, rotation=0,fontweight='bold')\nplt.yticks([])\nadd_value_labels(ax10)\n\n# HasCrCard\nplt.subplot(5, 2, 4)\nax5 = plt.gca()\nax5.set_title('HasCrCard', fontsize=22, fontweight='bold')\nsns.countplot(x='HasCrCard', palette='viridis', data=base_original, ax=ax5)\nplt.xlabel('') \nplt.ylabel('') \nplt.xticks(fontsize=15, rotation=0,fontweight='bold')\nplt.yticks([])\nadd_value_labels(ax5)\n\n# IsActiveMember\nplt.subplot(5, 2, 5)\nax6 = plt.gca()\nax6.set_title('IsActiveMember', fontsize=22, fontweight='bold')\nsns.countplot(x='IsActiveMember', palette='viridis', data=base_original, ax=ax6)\nplt.xlabel('') \nplt.ylabel('') \nplt.xticks(fontsize=15, rotation=0,fontweight='bold')\nplt.yticks([])\nadd_value_labels(ax6)\n\n# Card Type\nplt.subplot(5, 2, 6)\nax10 = plt.gca()\nax10.set_title('Card Type', fontsize=22, fontweight='bold')\nsns.countplot(x='Card Type', palette='viridis', data=base_original, ax=ax10)\nplt.xlabel('') \nplt.ylabel('') \nplt.xticks(fontsize=15, rotation=0,fontweight='bold')\nplt.yticks([])\nadd_value_labels(ax10)\n\n# Exited\nplt.subplot(5, 2, 7)\nax7 = plt.gca()\nax7.set_title('Exited: churn variable', fontsize=22, fontweight='bold')\ncustom_palette = ['green', 'red']\nsns.countplot(x='Exited', palette=custom_palette, data=base_original, ax=ax7)\nplt.xlabel('') \nplt.ylabel('') \nplt.xticks(fontsize=15, rotation=0,fontweight='bold')\nplt.yticks([])\nadd_value_labels(ax7)\n\n\nax7.set_xticks([0, 1])  # Define os ticks manualmente\nax7.set_xticklabels(['Não', 'Sim'], fontsize=15, fontweight='bold')  # Rótulos personalizados\nadd_value_labels(ax7)\n\n\n# ajusta a distância entre os gráficos\nplt.subplots_adjust(hspace=0.3, wspace=0.1)\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#%% Variável TARGET em relação as demais variáveis \n\nplt.figure(figsize=(20, 25))\n\ndef add_legend(ax):\n    \"\"\"Adiciona a legenda no canto superior direito e garante que os rótulos sejam exibidos\"\"\"\n    handles, labels = ax.get_legend_handles_labels()\n    if not handles:\n        # Se não houver handles, adicione manualmente\n        handles = [plt.Rectangle((0,0),1,1, color=c) for c in ['green', 'red']]\n        labels = ['Not Exited', 'Exited']\n    # Adiciona a legenda fora da área das barras\n    ax.legend(handles, labels, loc='upper left', fontsize=14, title='Exited', title_fontsize='13',\n              bbox_to_anchor=(1.0, 1))  # Ajusta a posição da legenda para fora das barras\n\n# Geography\nplt.subplot(5, 2, 1)\ncounts = base_original.groupby(['Geography', 'Exited']).size().unstack().fillna(0)\nax = counts.plot(kind='bar', stacked=True, color=['green', 'red'], ax=plt.gca())  \nplt.title('Exited by Geography', fontsize=22, fontweight='bold')\nplt.xlabel('Geography', fontsize=16)\nplt.ylabel('', fontsize=16)\nplt.xticks(fontsize=14, rotation=0,fontweight='bold')\nplt.yticks(fontsize=14)\nadd_legend(ax)\n\n# Gender\nplt.subplot(5, 2, 2)\ncounts = base_original.groupby(['Gender', 'Exited']).size().unstack().fillna(0)\nax = counts.plot(kind='bar', stacked=True, color=['green', 'red'], ax=plt.gca()) \nplt.title('Exited by Gender', fontsize=22, fontweight='bold')\nplt.xlabel('Gender', fontsize=16)\nplt.ylabel('', fontsize=16)\nplt.xticks(fontsize=14, rotation=0,fontweight='bold')\nplt.yticks(fontsize=14)\nadd_legend(ax)\n\n# NumOfProducts\nplt.subplot(5, 2, 3)\ncounts = base_original.groupby(['NumOfProducts', 'Exited']).size().unstack().fillna(0)\nax = counts.plot(kind='bar', stacked=True, color=['green', 'red'], ax=plt.gca())  \nplt.title('Exited by NumOfProducts', fontsize=22, fontweight='bold')\nplt.xlabel('NumOfProducts', fontsize=16)\nplt.ylabel('', fontsize=16)\nplt.xticks(fontsize=14, rotation=0,fontweight='bold')\nplt.yticks(fontsize=14)\nadd_legend(ax)\n\n# HasCrCard\nplt.subplot(5, 2, 4)\ncounts = base_original.groupby(['HasCrCard', 'Exited']).size().unstack().fillna(0)\nax = counts.plot(kind='bar', stacked=True, color=['green', 'red'], ax=plt.gca())  \nplt.title('Exited by HasCrCard', fontsize=22, fontweight='bold')\nplt.xlabel('HasCrCard', fontsize=16)\nplt.ylabel('', fontsize=16)\nplt.xticks(fontsize=14, rotation=0,fontweight='bold')\nplt.yticks(fontsize=14)\nadd_legend(ax)\n\n# IsActiveMember\nplt.subplot(5, 2, 5)\ncounts = base_original.groupby(['IsActiveMember', 'Exited']).size().unstack().fillna(0)\nax = counts.plot(kind='bar', stacked=True, color=['green', 'red'], ax=plt.gca()) \nplt.title('Exited by IsActiveMember', fontsize=22, fontweight='bold')\nplt.xlabel('IsActiveMember', fontsize=16)\nplt.ylabel('', fontsize=16)\nplt.xticks(fontsize=14, rotation=0,fontweight='bold')\nplt.yticks(fontsize=14)\nadd_legend(ax)\n\n# Complain\nplt.subplot(5, 2, 6)\ncounts = base_original.groupby(['Complain', 'Exited']).size().unstack().fillna(0)\nax = counts.plot(kind='bar', stacked=True, color=['green', 'red'], ax=plt.gca())  \nplt.title('Exited by Complain', fontsize=22, fontweight='bold')\nplt.xlabel('Complain', fontsize=16)\nplt.ylabel('', fontsize=16)\nplt.xticks(fontsize=14, rotation=0,fontweight='bold')\nplt.yticks(fontsize=14)\nadd_legend(ax)\n\n# Satisfaction Score\nplt.subplot(5, 2, 7)\ncounts = base_original.groupby(['Satisfaction Score', 'Exited']).size().unstack().fillna(0)\nax = counts.plot(kind='bar', stacked=True, color=['green', 'red'], ax=plt.gca())  \nplt.title('Exited by Satisfaction Score', fontsize=22, fontweight='bold')\nplt.xlabel('Satisfaction Score', fontsize=16)\nplt.ylabel('', fontsize=16)\nplt.xticks(fontsize=14, rotation=0,fontweight='bold')\nplt.yticks(fontsize=14)\nadd_legend(ax)\n\n# Card Type\nplt.subplot(5, 2, 8)\ncounts = base_original.groupby(['Card Type', 'Exited']).size().unstack().fillna(0)\nax = counts.plot(kind='bar', stacked=True, color=['green', 'red'], ax=plt.gca())  \nplt.title('Exited by Card Type', fontsize=22, fontweight='bold')\nplt.xlabel('Card Type', fontsize=16)\nplt.ylabel('', fontsize=16)\nplt.xticks(fontsize=14, rotation=0,fontweight='bold')\nplt.yticks(fontsize=14)\nadd_legend(ax)\n\n# Ajustar a distância entre os gráficos\nplt.subplots_adjust(hspace=0.7, wspace=0.3)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Variaveis Dummies e Correlações ","metadata":{}},{"cell_type":"code","source":"# Dumizando\n\n# Transformando colunas específicas em tipo object usando .loc para evitar o Warning\ncols_to_transform = ['HasCrCard', 'IsActiveMember', 'Geography', 'Gender', 'Card Type']\ndf.loc[:, cols_to_transform] = df[cols_to_transform].astype('object')\n\n\n\n# Gerando as dummies\ndf_dummies = pd.get_dummies(df,\n                           columns=['HasCrCard',\n                                    'IsActiveMember', \n                                    'Geography',\n                                    'Gender',\n                                    'Card Type'],\n                           dtype=int,\n                           drop_first=False)\n\n\n#Transformando Target em numérica\ndf_dummies['Exited'] = df_dummies['Exited'].astype('int64')\n\n\n\n#verificando tipos gerados\ndf_dummies.dtypes","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#%%Analises gráficas: correlação das variaveis Numéricas \n\ncorrelation_matrix = df_dummies.corr().round(2)\ncorrelation_matrix\n\n# Mapa de calor das variaveis quanti\nplt.figure(figsize=(30, 20))\nheatmap = sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\",\n                      cmap=plt.cm.Blues,\n                      annot_kws={'size': 15}, vmin=-1, vmax=1)\nheatmap.set_xticklabels(heatmap.get_xticklabels(), fontsize=17)\nheatmap.set_yticklabels(heatmap.get_yticklabels(), fontsize=17)\ncbar = heatmap.collections[0].colorbar\ncbar.ax.tick_params(labelsize=17)\nplt.title('Correlação das Variáveis Quantitativas', fontsize=25)\nplt.show()\n\n\n#apresentaram correlacao alta, para evitar multicolinearidade foram removidas \ndf_dummies = df_dummies.drop(columns=['HasCrCard_0','IsActiveMember_0','Gender_Female','Complain'])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Separação Treino e Teste","metadata":{}},{"cell_type":"code","source":"#X ---> Variáveis explicativas \n\n#Y ---> Evento de estudo (variável TARGET)\n\nX = df_dummies .drop('Exited', axis=1)\n\ny =  df_dummies['Exited']\n\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n\n\n# Verificando a proporção de eventos de churn (TARGET) nas bases de TREINO e TESTE \n\n# Contando os valores \nchurn_counts_train = y_train.value_counts()\nchurn_counts_test = y_test.value_counts()\n\n# Criando o plot com subplots lado a lado\nfig, axs = plt.subplots(1, 2, figsize=(20, 10))\n\n# Adicionando título geral ao plot\nfig.suptitle('Proporção da Variável Churn entre Treino e Teste', fontsize=35)\n\n#definindo a paleta de cor padrao a ser usada nos dois graficos \ncmap = plt.get_cmap('viridis', 2)\n\n# Gráfico da base de treino\nbars_train = axs[0].bar(churn_counts_train.index, churn_counts_train.values, color=cmap(range(2)))\naxs[0].set_title('Base de Treino', fontsize=25)\naxs[0].set_xlabel('Churn', fontsize=20)\naxs[0].set_ylabel('Contagem', fontsize=20)\naxs[0].set_xticks([0, 1])\naxs[0].set_xticklabels(['0', '1'], fontsize=20)\n\n# Ocultando os valores do eixo y\naxs[0].set_yticklabels([])\n\n# Adicionando rótulos de dados nas barras da base de treino com valor absoluto e percentual\ntotal_train = churn_counts_train.sum()\nfor bar in bars_train:\n    count = int(bar.get_height())\n    percentage = round(count / total_train * 100)  # Arredonda a porcentagem\n    label = f'{count} ({percentage}%)'  # Exibe o valor absoluto e o percentual\n    axs[0].text(bar.get_x() + bar.get_width() / 2, bar.get_height() / 2, \n                label, ha='center', color='gray', fontsize=25, weight='bold')\n\n# Gráfico da base de teste\nbars_test = axs[1].bar(churn_counts_test.index, churn_counts_test.values, color=cmap(range(2)))\naxs[1].set_title('Base de Teste', fontsize=25)\naxs[1].set_xlabel('Churn', fontsize=20)\naxs[1].set_ylabel('Contagem', fontsize=20)\naxs[1].set_xticks([0, 1])\naxs[1].set_xticklabels(['0', '1'], fontsize=20)\n\n# Ocultando os valores do eixo y\naxs[1].set_yticklabels([])\n\n# Adicionando rótulos de dados nas barras da base de teste com valor absoluto e percentual\ntotal_test = churn_counts_test.sum()\nfor bar in bars_test:\n    count = int(bar.get_height())\n    percentage = round(count / total_test * 100)  # Arredonda a porcentagem\n    label = f'{count} ({percentage}%)'  # Exibe o valor absoluto e o percentual\n    axs[1].text(bar.get_x() + bar.get_width() / 2, bar.get_height() / 2, \n                label, ha='center', color='gray', fontsize=25, weight='bold')\n\n# Ajustar o layout para evitar sobreposição\nplt.tight_layout(rect=[0, 0, 1, 0.95])  # Deixa espaço para o título principal\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#%% Testando Multicolinearidade na base de treino\n\n#Aqui é só para morrer de certeza, para evitar que o modelo treine errado ou sofra com multicolinearidade. \n\n# todo esse processo de tirar as variaveis que tem alta correlacao com a variavel target pode ser analisado se realmente é necessario, a depender do modelo \n# existem modelos que capturam bem isso e não são afetados pela multicolinearidade, nesse estudo vamos testar das duas formas, com e sem essas variáveis. \n\nteste_multco_treino = pd.concat([X_train,y_train], axis = 1)\n\ncorrelation_matrix_treino = teste_multco_treino.corr().round(2)\ncorrelation_matrix_treino\n\n# Mapa de calor das variaveis quanti (SEM COMPLAIN)\nplt.figure(figsize=(30, 20))\nheatmap = sns.heatmap(correlation_matrix_treino, annot=True, fmt=\".2f\",\n                      cmap=plt.cm.viridis_r, # é importante notar que a paleta de cores viridis (ou viridis_r para o inverso de cores) é uma paleta especial \n                                             # para facilitar a visualizacao por pessoas com dificuldades, como os daltonicos. \n                      annot_kws={'size': 15}, vmin=-1, vmax=1)\nheatmap.set_xticklabels(heatmap.get_xticklabels(), fontsize=17)\nheatmap.set_yticklabels(heatmap.get_yticklabels(), fontsize=17)\nplt.title('Correlação das Variáveis Quantitativas na Base de Treino',fontsize=25)\ncbar = heatmap.collections[0].colorbar\ncbar.ax.tick_params(labelsize=17)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Analise e tratamento de Outliers ","metadata":{}},{"cell_type":"code","source":"#%% analise de outliers das variaveis na base de treino \n\n\n#avariaveis analisadas (numéricas)\nvariaveis = [\n    'CreditScore',\n    'Age',\n    'Tenure',\n    'Balance',\n    'NumOfProducts',\n    'EstimatedSalary',\n    'Satisfaction Score',\n    'Point Earned'\n]\n\n# subplots\nplt.figure(figsize=(12, 8))\n\n# boxplots separados para cada variável\nfor i, var in enumerate(variaveis):\n    plt.subplot(3, 3, i + 1)  # 3 linhas e 3 colunas\n    sns.boxplot(y=teste_multco_treino[var],\n               boxprops=dict(facecolor='lightblue'))  # Cor interna do boxplot)  \n    plt.title(f'Boxplot {var}', fontsize=12)\n\n\n#  título geral\nplt.suptitle('Análise de Outliers nas Variáveis(treino) - antes de \"winsorization\" ', fontsize=20)\n\n# Ajuste de layout\nplt.tight_layout(rect=[0, 0, 1, 0.95])  # Ajuste de layout sem sobrepor o título\nplt.show()\n\n\n\n\n#aplicando procedimento de truncamento ou winsorization nos outliers\n\n# ---> substitui os outliers pelos valores dos limites inferior e superior, \n#de acordo com a posicao de cada outliers na distribuição dos dados\n\n# Função para tratar outliers\ndef tratar_outliers(df, coluna):\n    Q1 = df[coluna].quantile(0.25)\n    Q3 = df[coluna].quantile(0.75)\n    IQR = Q3 - Q1\n    limite_inferior = Q1 - 1.5 * IQR\n    limite_superior = Q3 + 1.5 * IQR\n    \n    # Substitui outliers pelo limite inferior ou superior\n    df[coluna] = np.where(df[coluna] < limite_inferior, limite_inferior, df[coluna])\n    df[coluna] = np.where(df[coluna] > limite_superior, limite_superior, df[coluna])\n\n# Aplicando a função nas variáveis \nvariaveis_para_tratar = ['Age', 'CreditScore', 'NumOfProducts']\n\nfor variavel in variaveis_para_tratar:\n    tratar_outliers(teste_multco_treino, variavel)\n    \n# subplot\nplt.figure(figsize=(12, 8))\n\n# boxplots separados para cada variável\nfor i, var in enumerate(variaveis):\n    plt.subplot(3, 3, i + 1)  # 3 linhas e 3 colunas\n    sns.boxplot(y=teste_multco_treino[var],\n               boxprops=dict(facecolor='green'))  # Cor interna do boxplot)  # Usar o nome da variável diretamente\n            \n    plt.title(f'Boxplot {var}', fontsize=12)\n\n# título geral\nplt.suptitle('Análise de Outliers nas Variáveis(treino) - depois de \"winsorization\" ', fontsize=20)\n\n# Ajustando layout\nplt.tight_layout(rect=[0, 0, 1, 0.95])  # Ajusta o layout sem sobrepor o título\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#%% Separando novamente as bases de treino e teste depois de tratar os outliers APENAS na base de TREINO  \n\n#treino\n\nX_train=teste_multco_treino.drop('Exited', axis=1)\ny_train=teste_multco_treino['Exited']\n\n#teste\nbase_corrige_teste = pd.concat([X_test,y_test], axis = 1)\nX_test=base_corrige_teste.drop('Exited', axis=1)\ny_test=base_corrige_teste['Exited']\n\n\nprint('---------------------------------------')\nprint(X_train.isnull().sum())\nprint('---------------------------------------')\nprint('---------------------------------------')\nprint(X_train.dtypes)\nprint('---------------------------------------')\nprint('---------------------------------------')\nprint(y_train.value_counts())\nprint('---------------------------------------')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Modelagem: aplicando MLP \n\nVer se vale a pena testar modelo com as variaveis quev foram removidas por multicolinearidade. ","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport optuna\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import f1_score, confusion_matrix, roc_curve\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\nfrom datetime import datetime, timedelta\n\nprint('------------------------')\nprint(\"MLP - Multi-Layer Perceptron \")\nprint('------------------------')\n# início\nstart_time_utc = datetime.utcnow() - timedelta(hours=3)\nprint('------------------------')\nprint(\"Início:\", start_time_utc)\nprint('------------------------')\n\n# Exemplo de dados fictícios (use seus dados aqui)\n# X_train, X_test, y_train, y_test são os dados de treino e teste já definidos.\n# Para fins de exemplo, vamos assumir que os dados estão prontos.\n\n# Normalizando os dados de treinamento\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Aplicando SMOTE para oversampling\nsmote = SMOTE(random_state=42)\nX_train_res, y_train_res = smote.fit_resample(X_train_scaled, y_train)\n\n# Convertendo para tensores PyTorch\nX_train_tensor = torch.tensor(X_train_res, dtype=torch.float32).cuda()\ny_train_tensor = torch.tensor(y_train_res, dtype=torch.float32).cuda()\nX_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32).cuda()\ny_test_tensor = torch.tensor(y_test, dtype=torch.float32).cuda()\n\n# Função para criar o modelo MLP\ndef create_model(hidden_layer_sizes, activation='relu', solver='adam', alpha=0.00001, \n                 learning_rate='constant', learning_rate_init=0.0001, max_iter=200, batch_size=32, \n                 momentum=0.9, early_stopping=True, validation_fraction=0.1):\n    class MLP(nn.Module):\n        def __init__(self):\n            super(MLP, self).__init__()\n            self.layers = nn.ModuleList()\n            input_size = X_train_tensor.shape[1]\n            for units in hidden_layer_sizes:\n                self.layers.append(nn.Linear(input_size, units))\n                input_size = units\n            self.output = nn.Linear(input_size, 1)\n            self.activation_fn = torch.relu if activation == 'relu' else torch.tanh\n            self.sigmoid = nn.Sigmoid()\n\n        def forward(self, x):\n            for layer in self.layers:\n                x = self.activation_fn(layer(x))\n            x = self.sigmoid(self.output(x))\n            return x\n\n    model = MLP().cuda()\n    criterion = nn.BCELoss()\n\n    # Ajustando o otimizador de acordo com o parâmetro solver\n    if solver == 'adam':\n        optimizer = optim.Adam(model.parameters(), lr=learning_rate_init)\n    elif solver == 'sgd':\n        optimizer = optim.SGD(model.parameters(), lr=learning_rate_init, momentum=momentum)\n\n    return model, criterion, optimizer\n\n# Função de objetivo para o Optuna\ndef objective(trial):\n    # Definição dos hiperparâmetros\n    hidden_layer_sizes = trial.suggest_categorical('hidden_layer_sizes', [(50,), (100,), (50, 50)])\n    activation = trial.suggest_categorical('activation', ['relu', 'tanh'])\n    solver = trial.suggest_categorical('solver', ['adam', 'sgd'])\n    alpha = trial.suggest_loguniform('alpha', 0.00001, 0.01)\n    learning_rate = trial.suggest_categorical('learning_rate', ['constant', 'adaptive'])\n    learning_rate_init = trial.suggest_categorical('learning_rate_init', [0.0001, 0.01])\n    max_iter = trial.suggest_categorical('max_iter', [200, 500])\n    batch_size = trial.suggest_categorical('batch_size', [32, 64])\n    momentum = trial.suggest_categorical('momentum', [0.9, 0.95])\n    early_stopping = trial.suggest_categorical('early_stopping', [True])\n    validation_fraction = trial.suggest_categorical('validation_fraction', [0.1])\n\n    # Criando o modelo\n    model, criterion, optimizer = create_model(\n        hidden_layer_sizes=hidden_layer_sizes, activation=activation, solver=solver, \n        alpha=alpha, learning_rate=learning_rate, learning_rate_init=learning_rate_init,\n        max_iter=max_iter, batch_size=batch_size, momentum=momentum, early_stopping=early_stopping, \n        validation_fraction=validation_fraction\n    )\n\n    # Treinamento\n    for epoch in range(max_iter):\n        model.train()\n        optimizer.zero_grad()\n        output = model(X_train_tensor).squeeze()\n        loss = criterion(output, y_train_tensor)\n        loss.backward()\n        optimizer.step()\n\n    # Avaliação\n    model.eval()\n    y_pred_prob_test = model(X_test_tensor).cpu().detach().numpy().squeeze()\n    y_pred_test = (y_pred_prob_test > 0.5).astype(int)\n\n    # Cálculo das métricas\n    accuracy = accuracy_score(y_test, y_pred_test)\n    precision = precision_score(y_test, y_pred_test)\n    recall = recall_score(y_test, y_pred_test)\n    f1 = f1_score(y_test, y_pred_test)\n    roc_auc = roc_auc_score(y_test, y_pred_prob_test)\n\n    # Exibir as métricas\n    print('------------------------')\n    print(\"\\nMétricas do Conjunto de Teste para o Modelo Neural (Cenário 3):\")\n    print(f\"ROC AUC: {roc_auc:.4f}\")\n    print(f\"Acurácia: {accuracy:.4f}\")\n    print(f\"Precisão: {precision:.4f}\")\n    print(f\"Revocação: {recall:.4f}\")\n    print(f\"F1-Score: {f1:.4f}\")\n    print('------------------------')\n    print('------------------------')\n\n    # Matriz de Confusão\n    cm = confusion_matrix(y_test, y_pred_test)\n\n    plt.figure(figsize=(10, 7))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Classe 0', 'Classe 1'], yticklabels=['Classe 0', 'Classe 1'])\n    plt.title('Matriz de Confusão')\n    plt.xlabel('Predito')\n    plt.ylabel('Real')\n    plt.show()\n\n    # Curva ROC-AUC\n    fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob_test)\n    plt.figure(figsize=(10, 7))\n    plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (F1-Score = {f1:.2f})')\n    plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n    plt.title('Curva ROC-AUC')\n    plt.xlabel('Taxa de Falsos Positivos')\n    plt.ylabel('Taxa de Verdadeiros Positivos')\n    plt.legend(loc='lower right')\n    plt.show()\n\n    return f1\n\n# Executando a otimização\nstudy = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=20)\n\nprint(f\"Melhores parâmetros: {study.best_params}\")\n\n# início\nprint('------------------------')\nprint(\"Início:\", start_time_utc)\nprint('------------------------')\n\n# fim\nend_time_utc = datetime.utcnow() - timedelta(hours=3)\nprint('------------------------')\nprint(\"Fim:\", end_time_utc)\nprint('------------------------')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}